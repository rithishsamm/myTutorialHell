### Introduction to Prompt Engineering:

Refs: [Prompt Engineering Guide](https://www.promptingguide.ai/)
Description:
This session lays the foundation for mastering prompt engineering—an essential skill for building and optimizing AI agents. Learn to craft effective prompts, control outputs, and guide language models with precision. We’ll cover best practices, real-world use cases, and frameworks to help you communicate with AI systems efficiently and creatively. A must-attend for anyone serious about harnessing the full power of large language models.

---

Agenda: 
1) Will just interpret and how to use the [Prompt Engineering Guide](https://www.promptingguide.ai/) in brief,
2) and use the OpenAI API Platform - [OpenAI Platform](https://platform.openai.com/) -> Settings -> [Billing](https://platform.openai.com/settings/organization/billing/overview)
3) Interrelation between these two and making the agents work for us in ease. 

---

## 1) What is Prompt Engineering 
As per [Prompt Engineering Guide](https://www.promptingguide.ai/), 

> [!NOTE] Prompt Engineering
> Prompt engineering is a relatively new discipline for developing and optimizing prompts to efficiently use language models (LMs) for a wide variety of applications and research topics. Prompt engineering skills help to better understand the capabilities and limitations of large language models (LLMs).
> 
> The objective for **Prompt Engineering** is nothing but simply giving instructions. 

In order to give instructions and get the job done out of it, we first need to know what to do, how to do and give instructions. How you can give the job when you know nothing about the job! Simple logic. 

LLM is such entity which is totally dumb. We should be able to give instructions properly inorder for it to do things as we say. Simply WYSIWYG.

---
THERE IS A DIFFERENCE BETWEEN THE [ChatGPT](https://chatgpt.com/) (a chatbot, an end user product that uses `LLM`, simply a byproduct) and the [OpenAI](https://openai.com/) (the actual model, that we make use of it to make it work for us/or build something out of it.) which can be used in [OpenAI Platform](https://platform.openai.com/)


**The [Prompt Engineering Guide](https://www.promptingguide.ai/), here is for our reference and understanding. Will keep it as a gist and follow along with the ideas, will not plagiarize it.**

Referring to the docs, it says
>  **Researchers** - use prompt engineering to improve the capacity of LLMs on a wide range of common and complex tasks such as question answering and arithmetic reasoning. 
>  
>  **Developers** - use prompt engineering to design robust and effective prompting techniques that interface with LLMs and other tools.

For the LLM to work, we need to give it and feed samples for it to run as it is, not to throw BS. For us to give input and get something out of it, there are `Prompting Techniques`. 
 
---

### Prompting Techniques:

> [!NOTE] TYPES OF [Prompting Techniques](https://www.promptingguide.ai/techniques):
> - [Zero-shot Prompting](https://www.promptingguide.ai/techniques/zeroshot)
> - [Few-shot Prompting](https://www.promptingguide.ai/techniques/fewshot)
> - [Chain-of-Thought Prompting](https://www.promptingguide.ai/techniques/cot)
> - [Meta Prompting](https://www.promptingguide.ai/techniques/meta-prompting)
> - [Self-Consistency](https://www.promptingguide.ai/techniques/consistency)
> - [Generate Knowledge Prompting](https://www.promptingguide.ai/techniques/knowledge)
> - [Prompt Chaining](https://www.promptingguide.ai/techniques/prompt_chaining)
> - [Tree of Thoughts](https://www.promptingguide.ai/techniques/tot)
> - [Retrieval Augmented Generation](https://www.promptingguide.ai/techniques/rag)
> - [Automatic Reasoning and Tool-use](https://www.promptingguide.ai/techniques/art)
> - [Automatic Prompt Engineer](https://www.promptingguide.ai/techniques/ape)
> - [Active-Prompt](https://www.promptingguide.ai/techniques/activeprompt)
> - [Directional Stimulus Prompting](https://www.promptingguide.ai/techniques/dsp)
> - [Program-Aided Language Models](https://www.promptingguide.ai/techniques/pal)
> - [ReAct](https://www.promptingguide.ai/techniques/react)
> - [Reflexion](https://www.promptingguide.ai/techniques/reflexion)
> - [Multimodal CoT](https://www.promptingguide.ai/techniques/multimodalcot)
> - [Graph Prompting](https://www.promptingguide.ai/techniques/graph)

Will cover why it is used, what is it for, why is it use for, how does it beneficial for the LLMs for it to work better in practice. 

>  Prompt Engineering is not just about designing and developing prompts, (can you develop a prompt on your ow
>  n to get the most out of it, is the question?)
>  Not a gimmick but an important skill to interface, interact, build with and understand the 

There are some Significant difference between using a Chat-bot and crafting a prompt engineered `LLM` honed in the playground, using that for our convenience, turning that into a source, converting the same to run it as an AI-Agent on its own is a whole different thing. 

Can do more by prompt engineering an `LLM` to improve the safety of its own and build new capabilities like augmenting `LLMs` with its specific, own domain knowledge for it to run on its own and also giving external tools to it to orchestrate multiple entities to run an environment as an agent.  

**There are some amount of engineering contained into each of the prompt that you craft.** 

*Will deconstruct and demystify those prompts and just jack  the art of prompt engineering and craft beautiful prompts.* 

> [!NOTE] about general LLMs
> Is a preset of basics stuffed right into it to get it run functionally and fundamentally.  
> - knows language
> - knows grammer
> - knows how to frame sentences 
> - knows communication
> - know how to converse with the right tone 
> - some models know some empathy
> **- IT IS ALSO A FANCY AUTO-COMPLETION**
But it does know the whole world!

==**In order to make the `LLM` work like something specific, train it to run on its own by giving domain specific context to it.** ==some models know some, some models doesn't. 

==**So, we should understand which model knows which and pass more context and knowledge to it for it to run on its own specific to its domain. Get that right to build new capabilities, knowledge, tools and get the best out of it.**==

---

> [!NOTE] Core to build an AI-Agent
> - Understand the model's capabilities
> - Pick all the datasets, knowledge for it to get domain specific
> - also aware of its limitations and illusion of thinking stuff
> - In order to get the Agent run along over our tools, give the Agent its access to all those tools to get work right. 

---

> [!NOTE] # [Introduction](https://www.promptingguide.ai/introduction)
> - [LLM Settings](https://www.promptingguide.ai/introduction/settings) 
> - [Basics of Prompting](https://www.promptingguide.ai/introduction/basics)
> - [Prompt Elements](https://www.promptingguide.ai/introduction/elements)
> - [General Tips for Designing Prompts](https://www.promptingguide.ai/introduction/tips)
> - [Examples of Prompts](https://www.promptingguide.ai/introduction/examples)

##### Just the overview and understanding of each of these topics:

### LLM Settings:

First, the OpenAI API Platform - [OpenAI Platform](https://platform.openai.com/) -> [Playground](https://platform.openai.com/playground) -> UI
Where you can able to,

NO PROMPTING AT ALL, ONLY SYSTEM MESSAGES. 
#### **Prompt**
 where you can able to 
 1) Select LLM Models - use **gpt 3.5 turbo (lowest token cost)**, (each have different pricing for it)
 2) `system` Message (ignore Functions for now),
 3) `user` - A chatbox
 4) `assistant` - LLM output
 5) and ensure the **`Chat Completion API`** checked on the top right corner. 

Ref: [[1. Prompt Engg#LLM SYSTEM'S ROLES]]

**UI Walk-through**:
- Select model - **gpt 3.5 turbo (lowest token cost, very older model)**
- Select **settings** (⚒) -> many settings as per our convenience. 
- For these settings, refer - **[LLM Settings](https://www.promptingguide.ai/introduction/settings)** - keep everything default as of now. - Regardless of anyt type of model.
- and ensure the **`Chat Completion API`** checked on the top right corner. (response API is relatively new and we are gonna look deep into Chat Completion since those LLM has been fundamentally thats the case. )

So, lets see what we can do here,
- Select `gpt-3.5-turbo`,
- System Message: Put ur prompt 
- Chat box - Enter there and get the output 
*(evaluate the model's quality)*

###### Practice 1:
- Enter a random stuff -> eg: `
-> system ` the sky is -> *Click* ` **Enter** `
- And it just auto-fills a random output by auto-completing it. 
>  this is **Just doing a fancy AUTO-COMPLETION**

SO, Observing here is that,
- We passed prompt in the **`system` message,
-> **`assistant`** - output.
- Got output in the **`assistant`** - output.
Clear memory as you work with it, or else, it keeps memory and spits the same. 

###### Practice 2:
Do the same but in the Chatbox as 
->  `user` - the sky is
- Doing the same, as similar to the same previously
- Auto-fills another random output. In the chatbox itself by 
->  `assistant` - output

It is not just answering, it just fills and auto-completing what we prompt.  

>  OK. That is **`Chat Completion API`** 

From here, we can also modify it and moderate the responses as we edited, 

###### Practice 3:
->  `user`: **`the sky is`**
->  `assistant` - CLEAR AND EDIT IT BACK TO -> **`blue`** (we just gave an response example and from there it follows up). Do play along by giving more,

->  `user`: **` the grass is `**
->  `assistant` response - Instead of throwing some auto-completion BS previously, says -> **`green`**.

**So, we moderated this way to respond in the certain way as we moderated it to be.** 

>  THE AUTO-COMPLETION that it did before doing all this - called **ZERO-SHOT PROMPTING**. 
>  Ref: 
>  [Zero-Shot Prompting](https://www.promptingguide.ai/techniques/zeroshot)
>   [[1. Prompt Engg#Prompting Techniques]]


NOW WILL DIG DEEP INTO [[1. Prompt Engg#**Prompt**]]
` Where you can able to 
` 1) Select LLM Models - use **gpt 3.5 turbo (lowest token cost)**, (each have different pricing for it)`
` 2) System Message (ignore Functions for now),`
` 3) A chatbox`
4) and ensure the **`Chat Completion API`** checked on the top right corner.

#### IN THE **PROMPTS** SECTION's Model selector's Settings ICON: 
##### 1. Temperature - thinking level regulator
Control Randomness: Lowering Results in less random completions. As the temperature approaches zero, the model will become repetitive and deterministic.  

**`Tldr`: HOW CRAZY A MODEL CAN BEHAVE TO MAX TO ITS NATURE.** (relates with and compliment with [[1. Prompt Engg#2. Top P (Top Probability)]])

**Practice 4:**
See that my practicing with the temperature maxxed out: 
> WARNING:  MAY EXHAUST YOUR TOKENS. Change values by `1.0.1+` not by `2 or 99`. Get you bankrupt. 

-> With **`Temperature: 1.0.1+`** : Throws refined detailed to its max out the model's capability.
-> With **`Temperature: 2`**: Throws random HASH and BS which doesn't capable of comprehending to throw out of it. 

>  **Referring to docs:**  - [LLM Settings](https://www.promptingguide.ai/introduction/settings)
>  ***Low Temperature:*** the lower the `temperature` - the more deterministic (fact based output instead of deciphering much about the conviction) the results in the sense that the highest probable next token is always picked. 
>  ***Higher Temperature***: - (go crazy and convey how max you can deliver back to) Increasing temperature could lead to more randomness, which encourages more diverse or creative outputs.

***When to use Low Temperature:*** Professional and based straight-forward, robotic, law is law, repetitive, deterministic, radical workloads and use-cases. Useful for Programming logic, decision logic and more. 

***When to use High Temperature:*** Diverse, artistic, thoughtful and Creative outputs. Suggests creative ideas and such. Applies in the field of Marketing, Inspiration, writing, brainstorming, production and much more. 

***Handle this very minute, mindful and carefully.*** Keep the **`temperature value: 1`**, as of now, will increase whenever necessary. 

> [!NOTE] Understanding TOKENS:
> Correlated to: [[1. Prompt Engg#3. Max Tokens]] - default: **2048**.
> Tokens: (mentioned under the response of the chatbox). Says:
> - 1. time to took to cook the response. 
> - 2. Input token - amount of token we took/sent as input to this model 
> - 3. Output token - how much it tokens for it to produce the output.
**TOKENS AREN'T LETTERS. Token = Group of three or four letters.** 

***Lower temperature value** - For fact-based QA to encourage more factual and concise responses.* 
***Higher temperature** - For poem generation or other creative tasks.*

***As we referred before that the temperature is correlated and compliments Top P - Top Probability, HOW COME?***

---

##### 2. Top P (Top Probability) - Spectrum of Confident level - Confidence/Certainty/Probability regulator
>  Controls diversity via nucleus sampling: **0.5 means half of all likely-hood-weighted options are considered**.
>  
>  A sampling technique with temperature, called nucleus sampling, where you can control how deterministic the model is. If you are looking for exact and factual answers keep this low. 
>  If you are looking for more diverse responses, increase to a higher value. 
>  If you use `Top P` it means that only the tokens comprising the `top_p` probability mass are considered for responses, so **a low `top_p` value selects the most confident responses.**
>   This means that a **high `top_p` value will enable the model to look at more possible words, including less likely ones, leading to more diverse outputs.**

**FOR `LLM` s it is Probability, for us, it is confidence.** 

Opposite of temperature.  Temperature has and we give freedom to think on itself to throw output. Regulating Confidence level of the `LLM`. 
- **Temperature - throws regardless of how confident it is about the output.** IS ABOUT HOW IT THINKS
-  **`top-p`,** give output only if you are certain and confident. IS ABOUT HOW IT OUTPUTS (more common, confident and certain).

Temperature: Think either radically or crazy and, Top-p: throw only if you are certain or nothing, NO BS. 

How confident the LLM is about the token that is throwing. `top_p` is probability mass. 

***WARNING: The general recommendation is to alter temperature or Top P but not both.*** Might hallucinate if it is messy configuration. 

---
##### 3. Max Tokens: 
Are **Max Length** - You can manage the number of tokens the model generates by adjusting the `max length`. Specifying a max length helps you prevent long or irrelevant responses and control costs.


---
##### 4. Stop Sequences: 
>  A `stop sequence` is a string that stops the model from generating tokens. Specifying stop sequences is another **way to control the length and structure of the model's response**.

As long as it was once a Chat-bot, there was no need for **Stop Sequences**. For AI-Agents, it has purpose. Stop sequence can be a list of words, numbers or whatever in  sequence. 

**Practice 5:** 
**Step Sequence: `11`**
-> **`system`:** Generate 20 games
-> **`assistant`:** generates only 10 games. 

---
##### 5. Frequency Penalty
>  How much you penalize new tokens based on their existing frequency in the text so far (how frequent the model throws certain token again and again). Decrease the model's likelihood to repeat the same line verbatim.

> ***Frequency Penalty** - The `frequency penalty` applies a penalty on the **next token proportional to how many times that token already appeared in the response and prompt.** The higher the frequency penalty, the less likely a word will appear again. **this setting reduces the repetition of words in the model's response by giving tokens that appear more a higher penalty.***

IF A WORD COMES IN REPEAT AND REPETITIVE. 
Applies for specific use cases. Like peoms (where we dont want few tokens/words them to repeat again and again in the summary.)


**Even `the` is even won't comes in repeat if restricted.** eg: already you have used number of `the` 's already, so don't use it again. 


---
##### 6. Presence Penalty
>  Whether to store logs for later retrieval. Logs are visible to you organization. 

>  ***Presence Penalty** - The `presence penalty` also applies a penalty on repeated tokens but, unlike the frequency penalty, **the penalty is the same for all repeated tokens**. A token that appears twice and a token that appears 10 times are penalized the same. This setting prevents the model from repeating phrases too often in its response. 
If you want the model to generate diverse or creative text, you might want to use a higher presence penalty. Or, if you need the model to stay focused, try using a lower presence penalty.*

Similar to [[1. Prompt Engg#5. Frequency Penalty]].
**The word `the` is used frequent from now on don't repeat again.** eg: already you have used number of `the` 's already, so don't use it again. 

Since the model could create more creative texts, moderate as per the convenience as  required. 

***WARNING: Similar to `temperature` and `top_p`, the general recommendation is to alter the frequency or presence penalty but not both.***

7**==Use all these setting as per the Requirement required for the usecase, else, ALL THE DEFAULT LLM SETTINGS JUST WORKS IN EASE, Regardless of any type of LLM.

**==DEFAULT `LLM Settings`:****
Response Format: `text`,
Temperature: `1`,
Max tokens: `2048`,
Stop Sequence: `   `
Top-p: `1,`
Frequency Penalty: `0.0`,
Presence Penalty: `0.0` ==
**Again - Regardless of any type of LLM, default settings applies the same**

---
Lets hold **Images**, **Real-time**, **Assistants**, **TTS** as of now. 

---
---

### Basics of PROMPTING:

Following to [[#Introduction to Prompt Engineering]], 

Next to LLM Settings,
**NOW COVERING [Basics of Prompting \| Prompt Engineering Guide](https://www.promptingguide.ai/introduction/basics)**

**THIS IS MORE OVER SIMILAR TO WHAT WE HAVE PRACTICED IN [[1. Prompt Engg#Practice 1]] an the following,** 

There we have seen,
- AUTO-COMPLETION API working,
- Prompts 
- Model Selection
- LLM Settings and Tuning. 
- System Message and Chatbox Playground, 
- Manipulated and moderated output. 

Here, Understand there are three different roles to Chat Models, 

---
##### LLM SYSTEM'S ROLES: 
> [!NOTE] LLM Roles:
> - **`user` + `assistant` = conversation**
> - **`system` message = dictate how the LLM `assistant` should function,** 
###### **`system`** 
`system` message - The `system` message is not required but helps to **set the overall behavior of the LLM - `assistant`**

###### **`user`** 
chatbox `user` input - a `user` message which you **can use to directly prompt the model**.

###### **`assistant`** 
LLM's alias - The `assistant` message in the example above **corresponds to the model response**. You can also define an `assistant` message **to pass examples of the desired behavior you want**.

**Example:**
###### Practice 5:
->  `system`: You can only answer to questions related to computer science. Say "I can't help you" for any other domain related questions. 
-> `user`: the sky is
-> `assistant`: I can't help you

This is the thing about AI-Agents and the `LLM` that we pass to give the Agent or Workflow.

---
### Prompting Formatting:
You can decode the same by selecting `code` option. And You can get to know how the communication works.

And there, we have ***edited and modified the prompt*** and the response for the LLM to behave in a certain manner - that is **Prompt Formatting.**  

---
---
### Elements of Prompting:

Thumb rule of a prompt that has to be taken place in:
> [!NOTE] #### A prompt should be composed with these four elements
> - **Instruction** - a specific task or instruction you want the model to perform. First to be in a prompt. 
> - **Context** - external information or additional context that can steer the model to better responses. More data added to the following tp the instructions given along. - can add more examples, usecases, scenarios and more.
> - **Input Data** - the input or question that we are interested to find a response for - actual question.
> - **Output Indicator** - the type or format of the output. - type of output that you expect.

$$
NOTE: stillWeAreIn-`Chat Completion API` 
$$

What this means? This is the mental model of a prompt:
Model:
```
Classify the text into neutral, negative, or positive

Text: I think the food was okay.

Sentiment:
```


Pass this as `user`.,
###### Practice 6:
-> `user` - Classify the text into neutral, negative, or positive. 
Text: I think the food was okay.
Sentiment:
->  `assistant` : Neutral

*Lets decipher the Prompt model and its elements:*
- ***Instruction** - Classify the text into neutral, negative, or positive*
- ***Input Data**: I think the food was okay.*
- ***Output Indicator**:*

Not mandatory that these are has to be presented but gives fresh output if followed. 
- The first element to a prompt has to be an **Instruction**. 
- No **Context** of added to the instructions passed above,
- **Input Data** - actual question - i think the food was OK,
- Sentiment is the **Output Indicator** of how the response should be. 

**Here, We can dictate the same of how the model should response as by giving the instructions to the - `system`** 
###### Practice 7:
-> `system` - Classify the text into neutral, negative and positive. 
-> `user` - Text: I think the food was okay.
-> `assistant` - Neutral

---

### Examples of Prompts

##### What it gets right: 
> [!NOTE] Topics:
> - [Text Summarization](https://www.promptingguide.ai/introduction/examples#text-summarization)
> - [Information Extraction](https://www.promptingguide.ai/introduction/examples#information-extraction)
> - [Question Answering](https://www.promptingguide.ai/introduction/examples#question-answering)
> - [Text Classification](https://www.promptingguide.ai/introduction/examples#text-classification)
> - [Conversation](https://www.promptingguide.ai/introduction/examples#conversation)
> - [Code Generation](https://www.promptingguide.ai/introduction/examples#code-generation)
> - [Reasoning](https://www.promptingguide.ai/introduction/examples#reasoning)



---

##### What it gets wrong: 
Refer: [Easy Problems That LLMs Get Wrong](https://arxiv.org/html/2405.19616v2)
Question Taxonomy:
It doesn't perform well when it comes to:

| Question Type   | Description                                                                                                                                                                                                                                                       |
| --------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Puzzle          | Logic-type puzzles that mimic the structure of popular questions found online but differ significantly in one or more critical aspects that make the questions much easier for humans. *Illusion of thinking*.                                                    |
| Spatial         | Requires visualising the arrangement or relative positions of objects in space, such as determining the order or position of items or simple navigation. *Recent models got better of spatial awareness and situation attentiveness, older ones sucks at these* . |
| Relational      | Involve understanding and inferring relationships or hierarchies between objects, concepts, or entities based on provided information.*Obvious*                                                                                                                   |
| Counting        | Simple numerical calculations such as counting to a maximum of ten or understanding quantities. *sucks at numbers*                                                                                                                                                |
| Linguistic      | Tests the understanding and use of language, including forming sentences with specific constraints or identifying unique characteristics of words and phrases. *messy at languages*                                                                               |
| Popular science | Straightforward questions that test for common scientific and mathematical misconceptions. *sucks at getting updated with science concepts*                                                                                                                       |

![LLMs Confidence Interval](https://arxiv.org/html/2405.19616v2/extracted/5636080/confidence-interval-white-paper.png)

BE CONSCIOUS WHILE HANDLING WITH THESE. 
**==AGAIN, JUST A FANCY PATTERN MATCHING MACHINE!==** 

*IT PERFORMS FAIR AT A DECENT AMOUNT, BUT BLUFFS WHEN THE COMPLEXITY INCREASES!* But recently it got better even when we define it to `system` s . Still a dumb but super PATTERN MATCHER. 

ADD:
```
12+196+138+206+122+307+35+135+20+201+4+3+2+1+14+21+221+149+244+134+280+33+127+27+196
```

-> `calculation`: 2818
-> `assistant` LLM: 2525

---

What to do about it? -
GIVE TOOLS WHICH THE `AI` CAN'T DO. 
>  -IF IT DOESN'T PERFORM MATH WELL, GIVE A CALCULATOR OR SOME SORT OF MATH TOOL TO IT (such as a shell, python, bc or what not. 

- No **Math**? - give a **CALCULATOR**
- No **Spatial Awareness**? - give a GIS system access,
- No **Popular concept**? - pass Research papers and data's to it. 
- No **Language**? - give the essential UNICODE and the language materials. 

Get yourself informed and decide:
- **When you get to to know what `LLM` does, let it do, 
- **when it know doesn't know what else that it do? - give appropriate tools to it and let it get the job done.**

**==PUT IT ALL TOGETHER AND MAKE IT WORK.==** To make it happen and first step to do this is that,
- Identifying the problem,
- Check whether the `Model` can do the job?
called **Feasibility Analysis.** 


THAT IS THE THING ABOUT `AI-Agents`,
LETS GET TO IT! THAT IS THE WHOLE PURPOSE!! 


---

# Types of Prompting:

These are nothing but just small small things which helps us get the best out of the `LLM` models. 
> [!NOTE] TYPES OF [Prompting Techniques](https://www.promptingguide.ai/techniques):
> - [Zero-shot Prompting](https://www.promptingguide.ai/techniques/zeroshot)
> - [Few-shot Prompting](https://www.promptingguide.ai/techniques/fewshot)
> - [Chain-of-Thought Prompting](https://www.promptingguide.ai/techniques/cot)
> - [Meta Prompting](https://www.promptingguide.ai/techniques/meta-prompting)
> - [Self-Consistency](https://www.promptingguide.ai/techniques/consistency)
> - [Generate Knowledge Prompting](https://www.promptingguide.ai/techniques/knowledge)
> - [Prompt Chaining](https://www.promptingguide.ai/techniques/prompt_chaining)
> - [Tree of Thoughts](https://www.promptingguide.ai/techniques/tot)
> - [Retrieval Augmented Generation](https://www.promptingguide.ai/techniques/rag)
> - [Automatic Reasoning and Tool-use](https://www.promptingguide.ai/techniques/art)
> - [Automatic Prompt Engineer](https://www.promptingguide.ai/techniques/ape)
> - [Active-Prompt](https://www.promptingguide.ai/techniques/activeprompt)
> - [Directional Stimulus Prompting](https://www.promptingguide.ai/techniques/dsp)
> - [Program-Aided Language Models](https://www.promptingguide.ai/techniques/pal)
> - [ReAct](https://www.promptingguide.ai/techniques/react)
> - [Reflexion](https://www.promptingguide.ai/techniques/reflexion)
> - [Multimodal CoT](https://www.promptingguide.ai/techniques/multimodalcot)
> - [Graph Prompting](https://www.promptingguide.ai/techniques/graph)


### Zero-shot Prompting - Baseline [.](https://www.promptingguide.ai/techniques/zeroshot)
No additional examples need for the Model to give a right output. EVERYTHING IS PRETTY STRAIGHT-FORWARD. prompt used to interact with the model won't contain examples or demonstrations. 

*Large-scale training makes these models capable of performing some tasks in a "zero-shot" manner.* When it know too much, we no need to punch in additional example/training data for it to do stuff. 

ZERO-SHORT high likely to work on bigger advanced models. This may not feasible and might need to give additional contexts, examples and a bit of training data needed for Small and dumb models. 

The zero-shot prompt directly instructs the model need not to have any additional examples. to perform a task without any additional examples to steer it.

###### Practice 8:
`user`:
```
Classify the text into neutral, negative or positive. 

Text: I think the vacation is okay.
Sentiment:
```

`assistant`:
```
Neutral
```

>  ***NOTE**:  that in the prompt above we didn't provide the model with any examples of text alongside their classifications, the LLM already understands "sentiment" -- that's the zero-shot capabilities at work.*

###### Practice 9:
`user`: the sky is
`assistant`: clear and blue with some clouds scattered across the horizon. 

---
### Few-shot Prompting [.](https://www.promptingguide.ai/techniques/fewshot)
Here, we give extra just a bit of example for the model to perform in this type of way to give output like. 

>  They still fall short on more complex tasks when using the zero-shot setting. Few-shot prompting can be used as a technique **to enable in-context learning where we provide demonstrations in the prompt to steer the model to better performance**.

Eg 1:
###### Practice 10:
->  `user`: the sky is
-> `assistant`: clear and blue with some clouds scattered across the horizon. 

Change the `assistant` response to: clear and blue. 

->  `user`: the ocean water is
->  `assistant`: crystal clear and turquoise. 

Eg 2:
->  `user`:
```
A "whatpu" is a small, furry animal native to Tanzania. An example of a sentence that uses the word whatpu is:
We were traveling in Africa and we saw these very cute whatpus.
 
To do a "farduddle" means to jump up and down really fast. An example of a sentence that uses the word farduddle is:
```

->  `assistant`:
```
When we won the game, we all started to farduddle in celebration.
```

We can observe that the model has somehow learned how to perform the task by providing it with just one example (i.e., 1-shot).

For more difficult tasks, we can experiment with increasing the demonstrations (e.g., 3-shot, 5-shot, 10-shot, etc.).

*NOTE: it seems the newer GPT models we are experimenting with are becoming more robust to even random formats. Even the older Models are getting better as it learns and as days pasts, but still be skeptical that these may not work always*.

##### Limitations of Few-shot Prompting[](https://www.promptingguide.ai/techniques/fewshot#limitations-of-few-shot-prompting)
Standard few-shot prompting works well for many tasks but is still not a perfect technique, especially when dealing with more complex reasoning tasks.

Eg 3:
->  `user`:
```
The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1. 

A: 
```

-> `assistant`
If we try this again, the model outputs the following:
```
Yes, the odd numbers in this group add up to 107, which is an even number.
```
**THIS IS A OLDER MODEL OUTPUT:** This is not the correct response, which not only highlights the limitations of these systems but that there is a need for more advanced prompt engineering.

**NEW MODEL OUTPUT**: 41. Gets right. + *NOTE: it seems the newer GPT models we are experimenting with are becoming more robust to even random formats. Even the older Models are getting better as it learns and as days pasts, b**ut still be skeptical that these may not work always***.


---
### Chain-of-Thought Prompting [.](https://www.promptingguide.ai/techniques/cot)

A continuous step by step - reasoning and thought models like DeepSeek works this way. 

Thought process PROMPTING. **chain-of-thought (CoT)** prompting **enables complex reasoning capabilities through intermediate reasoning step by step**. 

You can combine it with few-shot prompting to get better results on more complex tasks that require reasoning before responding.

Making to think AI step-by-step - **Chain-of-Thought Prompting [.](https://www.promptingguide.ai/techniques/cot)**


![https://www.promptingguide.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fcot.1933d9fe.png&w=1080&q=75[image](https://www.promptingguide.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fcot.1933d9fe.png&w=1080&q=75)

Here, 
-> **Standard Prompting** gave direct answers which is wrong, where 
-> **Chain-of-Thought** Prompting is that it goes through multiple processes to get the answer right. 
> Regardless of how large and superior or small and dumb models. 

Recent models, the assistants are doing **Chain-of-Thought** itself,  
Eg 4:  241 -(-241)+1
`system`: 241 -(-241)+1
`assistant`: = 482
`user`: 241 -(-241)+1
`assistant`:
```
241 -(-241)+1 -> 241 + 241+ 1
241+241+1= 482+1 = 483 
Therefore, 241-(-241)+1=483
```
Itself a **Chain-of-Thought**. Will see more of these to get this right effectively. 

##### ZERO-SHOT CoT Chain-of-Thought Prompting [.](https://www.promptingguide.ai/techniques/cot)
![https://www.promptingguide.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fzero-cot.79793bee.png&w=1080&q=75[image](https://www.promptingguide.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fzero-cot.79793bee.png&w=1080&q=75)

Also there is,
![https://www.promptingguide.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fauto-cot.642d9bad.png&w=1200&q=75[image](https://www.promptingguide.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fauto-cot.642d9bad.png&w=1200&q=75)


---
>  ***REST OF THESE TOPICS SPEAKS FOR ITSELF AND NOT SO ROOTED. WE SKIP BY REFEERING ALL THE SAME IN DOCS OR WILL UPDATE IN FUTURE.***
### Meta Prompting [.](https://www.promptingguide.ai/techniques/meta-prompting)

### Self-Consistency [.](https://www.promptingguide.ai/techniques/consistency)

### Generate Knowledge Prompting [.](https://www.promptingguide.ai/techniques/knowledge)

### Prompt Chaining [.](https://www.promptingguide.ai/techniques/prompt_chaining)

### Tree of Thoughts [.](https://www.promptingguide.ai/techniques/tot)

### Retrieval Augmented Generation [.](https://www.promptingguide.ai/techniques/rag)

### Automatic Reasoning and Tool-use [.](https://www.promptingguide.ai/techniques/art)

### Automatic Prompt Engineer [.](https://www.promptingguide.ai/techniques/ape)

### Active-Prompt [.](https://www.promptingguide.ai/techniques/activeprompt)

### Directional Stimulus Prompting [.](https://www.promptingguide.ai/techniques/dsp)

### Program-Aided Language Models [.](https://www.promptingguide.ai/techniques/pal)

### ReAct [.](https://www.promptingguide.ai/techniques/react)

### Reflexion [.](https://www.promptingguide.ai/techniques/reflexion)

### Multimodal CoT [.](https://www.promptingguide.ai/techniques/multimodalcot)

### Graph Prompting [.](https://www.promptingguide.ai/techniques/graph)

---

### LLM model's Pricing [.](https://platform.openai.com/docs/pricing)
What we have practiced here is,

##### Other models

| Model         | Input | Output |
| ------------- | ----- | ------ |
| gpt-3.5-turbo | $0.50 | $1.50  |

Will be used mainstream models, 

| Model                        | Input | Cached | Output |
| ---------------------------- | ----- | ------ | ------ |
| gpt-4.1-mini                 | $0.40 | $0.10  | $1.60  |
| gpt-4.1-nano                 | $0.10 | $0.025 | $0.40  |
| gpt-4.1 (rare use)           | $2.00 | $0.50  | $8.00  |
| o4-mini (recommended)        | $1.10 | $0.275 | $4.40  |
| o3-mini                      | $1.10 | $0.55  | $4.40  |
| o1-mini                      | $1.10 | $0.55  | $4.40  |
| gpt-4o (mainstream/prod use) | $2.50 | $1.25  | $10.00 |

---
---
---

CORE IDEA OF Prompt Engineering:
Prompting isn’t just asking the AI a question. It’s a deliberate, engineered input design process, and a critical skill when working with Large Language Models (LLMs).  
  
Let's breakdown the prompting techniques.  
  
✅ 1. Core Prompting Techniques  
▪ Zero-shot - No examples provided. Just the task.  
▪ One-shot - One example shown before the task.  
▪ Few-shot - A handful of examples used to teach patterns.  
  
🧠 2. Reasoning-Enhancing Techniques  
▪ Chain-of-Thought (CoT) - Encourage step-by-step reasoning.  
▪ Self-Consistency - Sample multiple CoTs; choose the best.  
▪ Tree-of-Thought (ToT) - Explore multiple reasoning paths (advanced).  
▪ ReAct - Combine reasoning steps with action/tool use (e.g., API calls).  
  
🧾 3. Instruction and Role-Based Prompting  
▪ Instruction prompting - Clear directives (“Summarize this…”).  
▪ System / Role prompting - Define persona or behavior (“You are a legal assistant”).  
▪ Hybrid (Instruction + Examples) - Combine clarity with few-shot grounding.  
  
⚙️ 4. Prompt Composition Techniques  
▪ Prompt chaining - Use one prompt’s output in the next.  
▪ Dynamic prompting - Inject real-time variables or context.  
▪ Meta prompting - Ask the model to improve or verify its own response.  
  
🖼️ 5. Multimodal Prompting  
▪ Image + text - Provide both visual and textual context.  
▪ Audio/Video + text - Use transcripts or sensory input (model-dependent, e.g., GPT-4o, Gemini 1.5).  
  
🧑‍⚕️ 6. Domain-Specific Prompting  
▪ Code prompting - Constrained, tool-specific inputs (e.g., Python, SQL).  
▪ Medical / Legal prompting - High-precision language with strict format and accuracy needs.  
  
🧪 7. Prompt Evaluation & Debugging  
(Not prompting techniques, but crucial tools.)  
▪ Prompt ablation - Remove elements to test contribution.  
▪ Injection testing - Evaluate prompt robustness in apps or agents.  
  
❌ What’s Not a Prompting Technique  
▪ RAG: A retrieval + generation architecture. Prompts are used inside it.  
▪ Agents / Tool-use systems - Orchestration frameworks (e.g., LangGraph, AutoGPT). Prompting is one component, not the technique itself.  
  
🔧 Prompting is no longer “just prompt engineering.” It’s system design.  If you're working with LLMs, know these cold.

![https://media.licdn.com/dms/image/v2/D4D22AQGX-Dk1tgrLtA/feedshare-shrink_800/B4DZhp8uKmGsAg-/0/1754124183576?e=1757548800&v=beta&t=J_fTTmjzw2PvRWmT70ifk18hdCP0voP1vswVA16f0Ag[1754124183576](https://media.licdn.com/dms/image/v2/D4D22AQGX-Dk1tgrLtA/feedshare-shrink_800/B4DZhp8uKmGsAg-/0/1754124183576?e=1757548800&v=beta&t=J_fTTmjzw2PvRWmT70ifk18hdCP0voP1vswVA16f0Ag)