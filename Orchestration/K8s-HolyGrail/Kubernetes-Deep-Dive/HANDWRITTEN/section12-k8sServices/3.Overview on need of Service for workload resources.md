# 3.  Overview on need of Service for workload resources

**THE NEED OF `SERVICE` FOR WORKLOAD RESOURCES.**

Say for example that are having a Workflow of a **`Deployment`** Object:
> **Workflow**: Deployment -> ReplicaSet -> POD
> 	`Deploy` -> creates an `rs` of that -> `rs` which have the `replica+Podtemplate` -> creates all the PODs in all the available nodes, based on the **PodTemplate**

The need of a **service**. Why do we are in need of a service to perform such cases. *eg, as  per this diagram,*

Illustratively,
![[svc.excalidraw]] 

Here, We are trying to create a `deployment` object. an `nginx` application for example. As per the nature of the `deploy` object, -> creates an `rs` -> creates `PODs` with the respective labels with all all the `replicas+podTemplateHash`. As the result of the `deployment` object,

> ==**`deploy -nginx` -> `rs: 3` -> POD1 , POD2, POD3**
**have been created.** ==

The thing is, 
say we have a frontend working on somewhere and  this `deployment` object is the backend. If me as userPOD have to access to these PODs 1, 2 and 3 working as the backend.  
**HOW? WILL WE BE REGISTERING ALL THESE IP TO THE FRONTEND DESPITE BEING THE IP's ARE EPHEMERAL?**
> 	Hypothetically, lets say we done the same. configured each of the POD's IP to the frontend app making the backend accessible and working fine.
unfortunately or by any chance, we have deleted or the PODs goes down and gets recreated/self healed. And the IPs gets changed being **ephemeral**. EVEN IF YOU DO SO KEEPING THINGS UPDATED! **What about rollbacks and rollouts?** will we reconfiguring all these over and over again to the Frontend IF IT HAS `LB` then?

**HOW TO APPROACH THIS ?**  **==Services==**
IF IT IS A MANAGED SERVICES, EACH WILL BE PROVIDING THEIR OWN LOAD BALANCER,
- AWS EKS - ELB
- AZURE AKS - ALB
- GCP GKE - LB 

IF IT IS FOR ON-PREM or SUCH, **K8s Providing its own LB via the services.** Here, in the frontend, it is enough to just refer to the services (with VirtualIP or with DNS Name). and that's enough.

`servicesLB.yaml` + `deploy.yaml`. Work is done. Like
![[svc.excalidrawYaml]]
WHAT IS THE KEY COMPONENT HERE FOR THESE INDIVIDUAL ELEMENTS TO WORK WITH EACH OTHER: **==SELECTOR==**

RULE: **SelectorLabels** eg: `app=A` = **PodLabels** `app=A`
In order for the service's selector labels to identify the PODs by matching the PODs Labels, **!IMP - SELECTOR ==Labels==** of the ***services*** even though its just a metadata, plays a key role in identifying the PODs and provisioning it to work with. 
Regardless of the state, the IPs and the nodes. We will be figure and making thing out with these one. **Services** having an LB *distributing the traffic* in round-robin fashion. 

==The way that we get to have a contact with these are with **VIP** - **VIRTUAL IP** Address or **DNS NAME**.== 
Every IP that gets assigned to a service is know as Virtual IP and also these services will have DNS name. 
- who assigns it
- how it get assigned
- how things work in and out

The easiest way to configure a load balancer is of using `service`, these applies to all the workload supports `replication` and voila! -> CORE VALUE AND USE OF THE SERVICE.

since we are using `replica` concept in our cluster by using the `deploy` -> deriving `rs`  / or straight up `rs`, `rc`, `sts` -> PODs out of it.
In order to distribute to traffic to each, instead of loading all into just one pod. For that, LB. To create an LB in K8s - **==`SERVICE`==**
No matter the number of just one or more. 

WILL COVER ALL THINGS ABOUT:
> K8s Component:  ==**Services**==, and types. 
all the interrogative and exclamatory factors of:
- What is
- Why
- Where to use it
- At what conditions and such

###### **tldr** - service:
THE CONCEPT OF **SERVICE** IS SAME. IT IS ALL ABOUT **==DISTRIBUTION==**, where the service identifies PODs using `labels` which are defined in it's **selector** of Service's manifest which is identical to the PODs `matchLabels` and `matchExpressions` and distribute. 


and will cover all the TYPES OF SERVICEs which are,
1) ClusterIP (default)
2) NodePort 
3) LoadBalancer `LB` for service
4) ExternalIP
5) ExternalName
6) Headless (ClusterIP: none)
with these TYPES OF SERVICES we can create services to do distribution in various kinds for different use case of distribution. 

WILL DIG DEEP INTO THE CRITICAL POINTS,

> K8s Component:  ==**Services**==, and types. 
- A way to provider logical abstraction to allow access to application running on set of PODs
- It will make sure the traffic is split to backend PODs managed by workload resources using **LoadBalancer** mechanism (round robin as default)
- We can create different **services** by passing `.spec.type= [CLusterIP(default), LoadBalancer, nodePort]` etc. 
- Backend PODs are integrated to **service** by means of **`Endpoint object`**
- **Service** has a single point of contact with DNS and backend PODs with unique IP addresses (dynamic)
- **Service** will be reachable on IP address as well, which is called as **ClusterIP** (*Virtual IP address* mechanism)
- **Service** *DNS names* are controlled by **CoreDNS** add-on K8s Cluster
- **Service** identifies backend targets (PODs) by `selector` (`.spec.selector`)
- **Service** can be created with `EndPoint` (default) or *without Endpoint (EndpointSlice Object)*
- Default protocol supported by **service**: `TCP (UDP and SCTP)` 
- **Service** can be identified with 2 Primary modes -> Environment variables and DNS
1) Environment Variables: *{SVCNAME}_SERVICE_HOST and {SVCNAME}_SERVICE_PORT*
2) DNS: `<svcname>.<namespace>.svc.cluster.local`


NOW, Will get to the critical points,
##### INTRODUCTION TO SERVICES:
###### A way to provider logical abstraction to allow access to application running on set of PODs
If we need to send traffic to multiple replicas in the backend of our apps in the cluster - **services**  
uhm why?


###### It will make sure the traffic is split to backend PODs managed by workload resources using **LoadBalancer** mechanism (round robin as default)
makes sure the traffic is split to backend PODs managed by workload resources using **LoadBalancer** mechanism (round robin as default) 

as we previously mentioned, 
`userPOD` -- req --> `service` with LB -- redirects to --> pod1, 2, 3 (derived from `deployment` workload resource) - IN A ROUND ROBIN FASHION EQUALLY DISTRIBUTING THE TRAFFIC ONE ON ONE. 


###### We can create different services by passing `.spec.type=[CLusterIP(default), LoadBalancer, nodePort]` etc. 
default service type = **ClusterIP**
We can create different services by passing 
>`.spec.type`=`serviceType`

If in need of specifying different type of port means, 
```yaml
type: serviceType
```

###### Backend PODs are integrated to **service** by means of **`Endpoint object`**
Services uses a component called **`Endpoint object`** in order to manage the resources shattered around the cluster. 
> will be creating a service `svc` -> `endpoint` object -> POD1, 2, 3

**`Endpoint object`** - knows all the pods we have, if anything or any pod gets down and gets recreated with new information, THE RESPONSIBILITY OF UPDATING THE NEW INFO OF THE NEWLY CREATED POD TO `LB`, DISTRIBUTING BY REDIRECTING THE TRAFFIC TO NEW PODs IS TAKEN CARE OF **`ENDPOINT OBJECT`**, plays a key role of adding and removing pods upgrades and deprecations.  

Like in Jenkins controller having agents. 


###### Service has a single point of contact with DNS and backend PODs with unique IP addresses (dynamic)
every service will have a VIP and DNS name
+
###### Service will be reachable on IP address as well, which is called as ClusterIP (*Virtual IP address* mechanism)

IN ORDER TO REACH OUT TO SERVICE, the Single point of contact (SPOC) for these Service `svc` is the 
- **==CLUSTERIP**
- **==DNS NAME==**
and the reason for this is as we mentioned earlier that there are no IP's and Name are persistent but ephemeral. meaning *temporary name and IP*. 

###### Service *DNS names* are controlled by **CoreDNS** add-on K8s Cluster
and these two SPOC of `svc`, 
- **==CLUSTERIP==** - assigned by `svc` itself,
- **==DNS NAME==** - `svc` dns names are resolved and controlled by a component named CoreDNS.
**CoreDNS** is a flexible and fast plugin based add-on DNS server written in Go. It can be used in various environments and integrates with Kubernetes, etcd, and cloud providers.

takes the responsibility of assigning dns names to . 

###### Service identifies backend targets (PODs) by selector (`.spec.selector`)
Service -> identifies Targets with the help of Labels using -> **`Selector`** 

###### Service can be created with `EndPoint` (default) or *without Endpoint (EndpointSlice Object)*
Defining `endpoint` is optional, not so mandatory. works  even if we don't mention it. 

###### Default protocol supported by service: `TCP (UDP and SCTP)` 
Default protocol of service: `TCP (UDP and SCTP)` 

###### Service can be identified with 2 Primary modes -> Environment variables and DNS
1) Environment Variables: *{SVCNAME}_SERVICE_HOST and {SVCNAME}_SERVICE_PORT*
2) DNS: `<svcname>.<namespace>.svc.cluster.local`
Two primary modes::
**environment variables** will be seen in the container of the POD. 
can also use, `dns` names: `<svcname>.<namespace>.svc.cluster.local`

**for env: (if you call the variables, it'll be like)**
*{SVCNAME}_SERVICE_HOST 
{SVCNAME}_SERVICE_PORT*

**for dns names:**
domain may differ for different K8s cluster. most of the time the syntax will be `svc.cluster.local`


NOW WILL GET INTO PRACTICALS, GETTING STARTED WITH `ClusterIP`.

---