- LoadBalancer service Introduction - Doc


---
# 15. Load Balancer service: Introduction
Load Balancer service Introduction - [Doc]

We have seen the `svc` types as ClusterIP(default), NodePort and now, 
IF YOU WANT TO ACCESS APPLICATIONS ON K8s CLUSTERS FROM OUTSIDE, - **Load Balancer**

`LB` as an `svc` type, debunked! 
- will see how it works
- how it differs than other `svc` types,
- how it differs between On-Prem to Cloud

If we notice, these `svc` are themselves an `LB` right? distributing all these traffic to all the relevant PODs. when `svc` itself an `LB`

**Then why `LB` separately as an `svc` type itself.** 
- The one we have saw are all works within the clusters
- This one is which are going to be placed/configure **outside** the K8s Clusters in order to reach to our apps. 
an **==LB outside the K8s cluster==** --> sending the traffic to the nodes -> that to the `svc`s  - and that to the all the respective PODs.
==`svc` Load Balancer==

**Key points of LB `svc` type:**
1) In order to implement external traffic load balancing, we need to create Service of` type: LoadBalancer `
2) Workflow: 
External Traffic -> Load Balancer -> NodePort (optional) -> Service ClusterIP -> PODs
3) Service LoadBalancer works under *Layer4 load balancing* as per the OSI Model
4) When we create a service, declare `type: LoadBalancer` under spec(`.spec.type=LoadBalancer)
5) We can use imperative approach as well to create a LoadBalancer service. 
```sh
kubectl expose workloadObject workloadObjName --port=8080 --target-port=80 --name=svcName --type=LoadBalancer
```
6) While using `EKS`, `AKS`, `GKE` etc. cloud K8s services, it uses Cloud Load Balancer `svc` which redirects traffic from the LB to backend Pod's based on configuration
7) In order to disable **NodePort** creation for LoadBalancer Service, set `spec.allocteLoadBalancerNodePort=false`,
8) If we need to set internal LoadBalancer for service on cloud, declare annotations (eg: AWS EKS)
```yaml
metadata:
  name: my-service
  annotations:
    service.beta.kubernetes.io/aws-load-balancer-internal: "true"
```

###### 1) In order to implement external traffic load balancing, we need to create Service of` type: LoadBalancer `
as we just mentioned, If we want to drive an external traffic to balance the load to the cluster and then distribute it inside into the applications - **LoadBalancer** `svc` type.


###### 2) Workflow: 
External Traffic -> Load Balancer -> NodePort (optional) -> Service ClusterIP -> PODs

***how does it flow?*** 
External Traffic (from the client or whatnot) -> Reaches to the **LB** `svc` type (which we configure outside the cluster) --> reaches `nodeport` (varies based on different cloud platforms, if on-prem it exists) if we configure which assess the node Machine's/VM's IP and port (**NodePort** is totally optional) --> **ClusterIP** `svc` --> **Pods**

this way the traffic flows from outside the K8s to the applications inside the cluster. 



###### 3) Service LoadBalancer works under *Layer4 load balancing* as per the OSI Model
**LB** `svc` works on L4 **Transport Layer**4 level Load Balancing (to the core). the layer which are next to just going digital to physical - **Network level load balancing**. not *application level lb*


###### 4) When we create a service, declare `type: LoadBalancer` under spec (`.spec.type=LoadBalancer)
```yaml
  type: LoadBalancer
```
```yml
spec:
  selector: #labels
	...
  ports:#ports
    ...

  type: NodePort
```
and the `svc` type will be `LoadBalancer`.


###### 5) We can use imperative approach as well to create a LoadBalancer service. 
```sh
kubectl expose workloadObject workloadObjName --port=8080 --target-port=80 --name=svcName --type=LoadBalancer
```
also, can use Imperative approach to create a **LoadBalancer** `svc` type.


###### 6) While using `EKS`, `AKS`, `GKE` etc. cloud K8s services, it uses *Cloud Load Balancer* `svc` which redirects traffic from the LB to backend Pod's based on configuration
if/when we use cloud or other managed services for K8s such as AWS EKS, Azure AKS, GCP GKE, Rancher, IBM Cloud, Oracle Cloud, Mirantis and such, 

Creating a K8s cluster inside these cloud or other managed services, No need of worrying about managing Load Balancing since it is a managed service for K8s. LB has been taken care. 

> **Need of `LB` is essential to create on to manage and distribute the flow of traffic in ease when we deploy things on-premise since we are the pilot** 
> For cloud or other services, managed services will take care of managing the rest on L4. 


###### 7) In order to disable **NodePort** creation for LoadBalancer Service, set `spec.allocteLoadBalancerNodePort=false`,
as we saw the **NodePort** `svc` is optional which gets created, to enable or disable it, set the `spec.allocteLoadBalancerNodePort`parameter to either **true** or **false**. 

If LB on-premise, create NodePort in order to redirect the traffic to the node. in some cases, need to disable it. To disable it
```sh
spec.allocteLoadBalancerNodePort=false
```
traffic reaches directly **LB** `svc` to the **ClusterIP** and to the PODs

###### 8) If we need to set internal LoadBalancer for service on cloud, declare annotations (eg: AWS EKS)
```yaml
metadata:
  name: my-service
  annotations:
    service.beta.kubernetes.io/aws-load-balancer-internal: "true"
```
In order to set or create Internal or external LoadBalancer for service on cloud, need to declare some parameters/annotations which is nothing but set of parameters to the object, kind of label but does tasks to change the function or behavior.  (eg: AWS EKS)
```yaml
metadata:
  name: my-service
  annotations:
    service.beta.kubernetes.io/aws-load-balancer-internal: "true"
```
the **LoadBalancer** type that we want to create. If you don't, it creates an internal phasing LoadBalancer as default (which is essential). 

On cloud in the area of load balancing, the load balancing are of two types,
- Internal Load balancing
- Internet phasing
==->tldr: The LoadBalancer svc type is of that we place it outside the cluster to manage traffic and distribute it to the application inside the cluster.  configuring this one varies for different platforms.==
 
Will see both of the same and observe how it behaves based on the platforms. simply on-prem and for cloud. 

In order to implement a L4-LoadBalancer Solution for K8s services on both on-prem or cloud, what are all the ways?
**Onprem (oss):**
1) MetalLB (*popular*)
2) OpenELB
3) PureELB
for on-prem, to deploy L4 LB top our clusters. 
**Cloud(managed services):** 
4) AWS - AWS NLB (Network LB)
5) Azure - ALB - Azure Load Balancer
6) GCP - GCP Cloud Load Balancing
for cloud, to deploy L4 LB top our clusters. 

WILL SEE HOW BOTH OF THESE WORKS!

---