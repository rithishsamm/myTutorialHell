- CronJob workflow (restartPolicy) - Doc


---
# 2. CronJob workflow (`restart Policy`)
CronJob workflow (restart Policy) - [Doc]

to check the available `apiVersion`'s objects to declare in the manifest. 
```sh
kubectl api-resources | grep resourceName
```
Lets create one. `cj.yaml` 
```yaml
apiVersion: batch/v1    #apiVersion for Jobs
kind: CronJob           #kind of object
metadata:               #all the boilerplate labels that to assign to the objects
  name: cj1             #name of the object as label
spec:
  schedule: "*/2 * * * *" #cron expression to schedule the job at a given time (every 2 minutes)
  timezone: "Asia/Kolkata" #timezone of the job
  jobTemplate:            #jobTemplate for the job
    spec:                 #spec of the job
      template:           #template for the job where you write PodTemplate spec
        spec:             #spec of the PodTemplate
          containers:     #containers of the PodTemplate
            - name: cj1    #name of the container
              image: ubuntu:latest #image of the container
              args:     #command to run in the container
                - /bin/bash
                - -c
                - date; echo Welcome to cronJob
           restartPolicy: OnFailure #restartPolicy of the container (restart the container if it fails)
```

verify resources:
```sh
kubectl get cj,jobs,po -o wide
```
```sh
watch kubectl get cj,jobs,po -o wide
```

Here,
```
NAME            cj1  #name of the job
SCHEDULE        */2 * * * * #cron expression
TIMEZONE        <none> #timezone
SUSPEND         False  #suspend
ACTIVE          0      #Jobs that ran 
LAST SCHEDULE   75s #lastJob's
AGE             2m20s #agr of cj  
CONTAINERS      cj1   #podsToRunCJ
IMAGES          ubuntu:latest #image
SELECTOR        <none> #selector
```
**Workflow**: `cj` --> triggers `jobs` at the given time -> jobs creates `Pods` to execute each job

here, it stops at a certain point of time. probably `3`, that is due to the limit set by a parameter `successfulJobsHistoryLimits: 3` WILL SEE ABOUT THIS DEDICATEDLY,

>While the jobs continues to does its thing, if you need to do an update or maintenance in-between, `suspend` the job.
```sh
kubectl edit cj/cjName
```
edit: `suspend=true`,

and verify back with, 
```sh
kubectl get cj,jobs,po -o wide
```
```
NAME            cj1  #name of the job
SCHEDULE        */2 * * * * #cron expression
...
SUSPEND         True  #suspend
...
```
jobs will be stopped and new ones will not be created. 

AND EVERY ASPECTS OF JOBS THAT WE HAVE SEEN ARE APPLIED HERE TOO: (delete the job or the POD, nothing happens and affects the `cron`, just the history of the `job` will be lost)
```sh
kubectl delete job/JobName
kubectl po pod/podName
```

**delete a `cronJob`**:
```sh
kubectl delete cj/cjName
```
when deleting a `cronJob`: deletes the `cron` -> `jobs` -> `pods`

THIS IS ALL ABOUT `CRON`,
- what is `cronJob`
- scheduling of `cronJob`
- handling the `cronJob`

---
