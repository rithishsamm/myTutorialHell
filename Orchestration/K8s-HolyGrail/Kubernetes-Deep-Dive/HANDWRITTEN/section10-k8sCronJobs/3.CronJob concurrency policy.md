
---
# 3. CronJob Concurrency policy

Automated Tasks with `cron-jobs`

Next, 
UNDERSTANDING **`CronJob`'s Concurrency policy**, an optional field that runs under the parameter of `.spec.concurrencyPolicy` for `cronJob`,

What is  **Concurrency policy** in the first place?
CronJobs creates jobs at any given time, the `Concurrency policy` defines and controls when it has to create a `job`. The default is `Allow`.

To understand this use case in brief,
So, if a `CronJob` executes a `job` to perform a task via the
POD. meanwhile, another one gets triggered while the first job is still running. Another `CronJob` triggers the same does the the same and the cycle repeats. 

**Concurrency Policy is the same managing all the CLUTTER BETWEEN ONE AND OTHER.**

In this **Concurrency policy**, we have three modes:
- Allow
- Forbid
- Replace

1) `Allow` - It just works as it is, what we just declare. Allows multiple Jobs to do its task simultaneously and **concurrently** not to worry about the previous job at all.
2) `Forbid` -  Don't run another job if an old Job that is already is on the run performing its task.
3) `Replace` - Run the new job performing the task replacing the old running job by stopping it.

Apply the same based on the appropriate scenarios, if else just proceed with the default.

**Will see this in practice,** using the same base template manifest to verify the default `concurrencyPolicy`.

###### Allow:
```sh
apiVersion: batch/v1
kind: CronJob
metadata:
  name: cj1
spec:
  schedule: "*/2 * * * *"
  jobTemplate:
    spec:
      template:
        spec:
          containers:
            - name: cj1
              image: ubuntu:latest
              args:
                - /bin/bash
                - -c
                - date; echo Welcome to cronJob
           restartPolicy: OnFailure
#same base template manifest to verify the default concurrencyPolicy
```
apply,
```sh
kubectl get po -o cj/cj.yaml
```

Will check the default `Concurrency Policy`:
```sh
kubectl get cj cjName -o yaml
kubectl get cj cjName -o yaml | grep concurrency
```
check the `concurrencyPolicy: Allow`, which has been applied by default.
>+ It keeps on piling up the Jobs and the PODs.

if to modify
```sh
kubectl edit cj cjName 
```
change the param to `ConcurrencyPolicy: `, save and exit. 

###### Replace:
==**The Older job gets terminated and `replace`d with with the new Jobs with an newID.==** 
to modify the `ConcurrencyPolicy: Replace`
imperatively,
```sh
kubectl edit cj cjName 
```
change the param to `ConcurrencyPolicy: Replace`, save and exit. 

or declaratively:
```yaml
spec:
  concurrencyPolicy: Replace
  schedule: "*/2 * * * *"
  # timezone: "Asia/Kolkata"
  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: OnFailure

```

Will apply the same with different manifest with executing a logic where we can see the practice of the the `Replace` Functionality in ease. 

Job has to triggering a POD executing a task continuously which to get trashed and get replaced by the new one and the cycle goes. TO OBSERVE THE BEHAVIOUR OF `ConcurrencyPolicy: Replace`

```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: cj1
spec:
  concurrencyPolicy: Replace
  schedule: "*/2 * * * *"
  # timezone: "Asia/Kolkata"
  jobTemplate:
    spec:
      template:
        spec:
          containers:
            - name: cj1
              image: ubuntu:latest
              args:
                - /bin/bash
                - -c
                - while true; do date; echo Welcome to cronJob ; sleep 10; done
          restartPolicy: OnFailure
```

after modifying, verify
```sh
kubectl get cj,jobs,po -o wide
watch kubectl get cj,jobs,po -o wide
kubectl get cj cjName -o yaml
```
```sh
kubectl logs podName
watch kubectl logs podName
```

resulting the old-pod to,
```
error - PodName not found in the namespace
```
**Will observe the function here, since the `ConcurrencyPolicy=Replace`, 
The Older job gets terminated and `replace`d with with the new Jobs with an newID.** 

THAT's WHATS UP!

###### Forbid,
another on is `Forbid`,
==**Don't run another job if an old Job that is already is on the run performing its task.==** 

same manifest but `concurrencyPolicy: Forbid`
```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: cj-replace
spec:
  concurrencyPolicy: Forbid
  schedule: "*/2 * * * *"
  jobTemplate:
    spec:
      template:
        spec:
          containers:
            - name: cj-replace
              image: ubuntu:latest
              args:
                - /bin/bash
                - -c
                - while true; do date; echo Welcome to cronJob ; sleep 10; done
          restartPolicy: OnFailure
```

edit the manifest,
- either delete and create
- or
```sh
kubectl replace --force -f cj/cjName.yaml
```
showing, `deleted` and `replaced,`

verify resources,
```sh
kubectl get cj,jobs,po -o wide
watch kubectl get cj,jobs,po -o wide
kubectl get cj cjName -o yaml
```
```sh
kubectl logs podName
watch kubectl logs podName
```

CLEANUP:
```sh
kubectl delete cj cjName
```

---
