## Section 4: K8S Workloads
### 1. Workload resources introduction
#### Kubernetes Workload Resources introduction - [Doc](obsidian://open?vault=tutorialHell&file=Orchestration%2Fk8engineers.com%2FKubernetes-Deep-Dive%2Foffl-raw-docs%2Fkubernetes%20deepdive%2Fsection4-workloads%2F1.%20Kubernetes%20Workload%20Resources%20introduction.docx)
#### 2.  Workload resource replication
#### Kubernetes workload resource replication - [Doc](obsidian://open?vault=tutorialHell&file=Orchestration%2Fk8engineers.com%2FKubernetes-Deep-Dive%2Foffl-raw-docs%2Fkubernetes%20deepdive%2Fsection4-workloads%2F2.%20Kubernetes%20workload%20resource%20repliaction.docx)
---
##### Section 4: K8S Workloads
### 1. Workload resources introduction
###### Kubernetes Workload Resources introduction - [Doc](obsidian://open?vault=tutorialHell&file=Orchestration%2Fk8engineers.com%2FKubernetes-Deep-Dive%2Foffl-raw-docs%2Fkubernetes%20deepdive%2Fsection4-workloads%2F1.%20Kubernetes%20Workload%20Resources%20introduction.docx)
So far, we been discussed about Workloads, means POD. 
>Previously  we have touched a note that,  
>IT IS NOT A BEST PRACTICE OR PEOPLE DON'T DEPLOY APPLICATIONS ON A SIMPLY STANDALONE, were they are very prone to failures caused by any means. can occur via system error, network error or application error.
AFTER SUCH CASES? AND THINGS GET RECOVERED AND THE NODE GETS SPAWNED? Will all the pods with our application exists on our node?
**NO! create manually by passing the same to kubectl** -
==DRAWBACK OF STANDALONE PODS== ALL THINGS CONTAINERS ARE TAKEN CARE BY `kubelet` no prob. WHAT IF THE WHOLE NODE GETS BRICKED?

**Concern**: we cannot deploy critical or any applications in such a loose environment.
so Solution? There are solutions. These concerns can be satisfied with the help of a set of 
**==WORKLOAD RESOURCES==**. IS IT DIFFERENT FROM POD? **YES**!
**If standalone**: all things manual
**If with Workload Resources:** 
Way things works is different, such as Functionality, handling the PODs Lifecycle policy is all different.

Will see all of that in brief.

K8s **Workload Resources** Introduction:
> [!workload resources:] **WORKLOAD RESOURCES:**
> **1) ReplicationController** 
> **2) ReplicaSet**
> **3) Deployment**
> **4) CronJobs**
> **5) DaemonSet**
> **6) Statefulset**
> **7) Jobs**
> **8) (followed by Jobs) -> Auto Clean-up for finished jobs**
VERY VERY IMPORTANT SHIT THAT MANAGES YOUR RESOURCES:

##### 1) ReplicationController: utmost first basic set of workload resource.
 **ReplicationController** is a basic choice that helps running multiple pods.  Replicate running identical multi-container application pods.  
In near future, the ReplicationController might get deprecated. Alternatively, ReplicaSet.

##### 2) ReplicaSet: replication-controller on steroids
Instead of ReplicationController, **ReplicaSet** is the go to solution for the same. **ReplicaSet** is a highly recommended to use for the same instead of ReplicationController.  Why? **ReplicaSet** is used in the backend with a resource named **Deployment**.

Moreover both **replica set** and **controller** both in terms of functionality and workings are same **except selecting the labels** - known as `selectors` which selects labels.
> `ReplicaSet` is the advanced feature of `replication-controller`. To use the same, we should be working with `Deployment`.  why?

##### 3) Deployment: 
**Deployment**: the basic component which we use to deploy applications on one or more than one pods.
- scale in scale out pods based on load
- roll back roll out (upgrade and downgrade applications)
In K8s Realtime environment, by default applications gets deployed based on the `deployment` component. not the components which are replica set, controller or pod. 

 Deployment is using ReplicaSet in the backend to create and deploy replicas with the help of defining actual and desired state. 
 > WTF IS EVEN A REPLICA? -> **==Creating Multiple Pods ad handling them by `kube-controller-manager` ==**, If anything goes wrong with the pod like failure, crash, brick, failed or even deleted either intentional or unintentional. 

 K8s will check a parameter called `desired-state` and `actual-state` in the pod creation manifest. With that, if anything occurs getting created or deleted above or below abiding that states. 
> Deletes if more than desired number gets created or created if there is below that desired number.

THESE ARE MANAGED BY K8s. These works with the help of Replica concept in the backend. Will see more about these in brief.

##### 4) DaemonSet : running pods in each and every node in the cluster including replication-controller for specialized usecases.
`DaemonSet` -  helps running applications on relevant pods in each and every node in the cluster including `replication-controller`. Ensures running atleast one pod on each and every node. 
> why or for any specialized purposes?
running pods for monitoring and observatory purposes, such as monitoring, logs, application, load, traffic and more.

For such cases, we will be deploying applications on kubernetes clusters using `DaemonSet`. will see further in detail.

##### 5) Statefulset: This way of deploying applications using Statefulset. 
All the above covered K8s **Workload Resources** such as ReplicationController, ReplicaSet, Deployment and DaemonSet are all **stateless**. You can proceed deploy application statelessly, these are the choices. 

If you want to deploy things applications state fully, `statefulset` is the go to choice. 

##### 6) Jobs and CronJobs
Jobs and CronJobs are nothing but to run a specific job, batch operation, script, function or process. 
Used for cases such as taking backups, snapshots, restoration and more -> Jobs and Cronjobs.
**Job** - Runs a specific task
**CronJobs** - Run specific tasks on specific time or interval. 

##### Auto-cleanup for finished jobs:
A functionality. As the name says as you know, cleans up the Jobs leftover. To remove/delete the jobs that are done doing such tasks - `Auto-cleanup for finished jobs`. If not cleaed up, they will persist still in the garbage collection in **`etcd`**. This process named Garbage Collection. 

> ALL THESE **`WORKLOAD RESOURCES`** MENTIONED HERE ARE ALL NOTHING BUT EXIST HER JUST OF ONE CORE MAIN OBJECTIVE ULTIMATELY IS TO 
> **CREATE PODS**. Thou creating pods, which are made possible with the help of all these `WORKLOAD RESOURCES`. - CREATING BUNCH OF PODs in a certain manner.
Not simply a blatant standalone PODS which are named `WORKLOADS` To run all our applications either way.

Will see all of these in detail further. 

---
#### 2.  Workload resource replication
###### Kubernetes workload resource replication - [Doc](obsidian://open?vault=tutorialHell&file=Orchestration%2Fk8engineers.com%2FKubernetes-Deep-Dive%2Foffl-raw-docs%2Fkubernetes%20deepdive%2Fsection4-workloads%2F2.%20Kubernetes%20workload%20resource%20repliaction.docx)

So far, We've covered **Workload** and **Workload Resources** and its types. 

**What is Workload resource replication in K8s?**
1) **RELIABILITY**:
To ensure that we have minimum number of PODs running on the cluster for application to be accessible without downtime if any. Any problem with the node where the relevant pod is running; 

eg: we have a standalone pod running on any one of the compute plane pod. Since you know the drawback for standalone pods is that, The pod gets terminated if any failure case by any means. Few minutes after, The respective node gets spawned. 
what happens next? Won't come up automatically. Its is manual passing kubectl or APICalls in order to spin up all these containers in the POD to run in it. which is not in control by K8s itself. THESE ALL WE KNOW!

> Here, i would like to bring in the concept called **`replication`**. which is nothing but, instead of running one single pod,
> RUNNING APPS on MULTIPLE PODs ON THE CLUSTER with more specialized metrics.

eg: CREATING MULTIPLE PODs. 
POD1 , POD2 AND POD3. These pods may or may not run on same, different or on all node whichever `kube-scheduler` chooses the same to deploy such PODs.

> If any one of the Pod goes down for instance. Since we are discussing concept named `Replication` using any of the replica based workload resource such as `replication-controller`, `replicaset` or `deployment`.
> These POD1, 2 and 3 where creating and controlled by them. If the pod gets deleted, automatically these **replication components** will spin up the same in ease with the parameters of **actual and desired state**. eg: if the desired is 3 but exist count is 2, K8s `controller manager` will tap in and send that msg to  `kube-scheduler` to schedule pods to the desired state equals to the actual state.

THESE PRACTICE = **==`REPLICATION`==**, replicating the containers. Meanwhile, the entities that gets replicated is only the **application** not the **data**. Replicating only the template. All the pods that are getting created by your **replication components** tries to ensure that  all the pods get the same container template not the data. The data replication part do exist and it is possible but that's for another topic. All pod should spinned up with the same template which same resource and specs but not the data.

=> THAT IS CONCEPT OF **`REPLICATION`**

 Here in the concept of ==**`reliability`**==, ensure that minimum number of PODs running on the cluster for the application to run without any downtime by any means.
> In the case of LB for these 3pods and if one gets failed, the traffic gets distributed to the rest of those two pods. 

2) **LOAD BALANCING**:
We can add **service object** to Load Balance the traffic so that load will be generated on specific POD running on same node or different node.

Load Balancing is an in-built functionality of K8s which is simply as **`service`**. 
what is K8s service in the nutshell: Service as the name same takes up a service in front and make it to take care of certain jobs. Static resource and id management for PODs, DNS, IPaddr, LB and more to be on the forefront.

BOTH COMBINED, WE CAN SPIN N NUMBER OF PODS WITH `REPLICATION`
AND HANDLE N NUMBER OF TRAFFIC DISTRIBUTED EQUALLY TO ALL THESE PODS WITH `LB`. By using `service` concept.

3) **SCALING**:
If we need to increase or decrease the number of POD for the replicas we can do it on. FYI. 
> as the name says, Scaling Pods.

eg: Three pods. application can handle enough traffic. Later, experiencing an unexpected spike? LB distributing to only one where two got failed. Now, the one is literally getting choked with traffic. 

Here, we can do the replicas in ease on the fly. 

Simply can able to spin up 
- number of pods
- wider the spec
who's gonna do the scale in and scale out? 
Similar to AWS Auto-scaling.

> ALL OF THESE POINTS ARE THE MAIN HIGHLIGHTS THAT WHY REPLICATION AND STUFFS MATTERS!

`KUBERNETES WORKLOAD RESOURCES`
****

 

