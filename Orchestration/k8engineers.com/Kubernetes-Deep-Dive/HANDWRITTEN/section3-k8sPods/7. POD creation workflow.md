POD creation workflow
###### Pod Creation Workflow -[Doc](obsidian://open?vault=tutorialHell&file=Orchestration%2Fk8engineers.com%2FKubernetes-Deep-Dive%2Foffl-raw-docs%2Fkubernetes%20deepdive%2Fsec3-k8s-pods%2F4.Pod%20Creation%20Workflow.docx)
TILL NOW WE HAVE SEEN CREATING PODS in both declarative and imperative method. **WILL SEE THE WORKFLOW OF A POD CREATION:** (some basic things to know how things works under the hood while we create pods).

Referring to the K8s Architecture: we have gone through referring that **there are multiple components exist in both the control plane and worker node - which eventually talks to each other.**

Just the basics: WILL UNDERSTAND IN BRIEF ABOUT THE SAME: AND ANSWERING TO THE QUESTIONS OF:
- what happens when we create or try to create a POD?
- What K8s does?
- **WHAT TF HAPPENS WHEN WE PASS INPUT TO `kubectl` to create or whatever to an object BTS in K8s?** 
-  How the input has been passed to the `cri-runtime` to create a container
- And how you get back the response or acknowledgment?

Will refer the flow diagram for the same:   (WE HAVE ALL THE RELEVANT COMPONENTS THAT EXIST INBETWEEN IN TERMS OF CREATING A POD)
![[Pasted image 20240827163448.png]]
 
`kubectl`  < - >  `kube-apiserver`  < - >  `etcd`  < - >  `scheduler`  < - > `kubelet`  < - > `containerd` / or `docker` if it is used as **`cri`**

**DECODING THE FLOWCHART:**
INPUT TO CREATE POD:
1) USER -> `kubectl`  --> `kube-apiserver`
*(---create Pod--->)*
-- **user** passes --> **pod creation request** will be sent via `kubectl` --> to `kube-apiserver`
2) Now, `kube-apiserver` --> will verify with `etcd` 
*(---write --->)*
3) `etcd` will store the config and respond back -->  to `apiserver`
*<---* )*user if exist/`api-server`
-- (to check and return data whether the resource already exist or not)
if already exists, spins up the POD!
if the resource doesn't exist, 
4) `apiserver` to user - creating those pods
*(<----) - already exists*
5) `apiserver` --> will pass it to the `scheduler`
*(---watch (new pod)--->)*
-- `scheduler` will analyze based on some metrics and algorithm to picks the suitable node to deploy the POD.
6) After deciding it, `scheduler` --> to `apiserver`, where that information 
*(<---bind pod---)*
gets stored in -> `etcd`. 
*(---write-->)*
>`etcd` can't talk to `scheduler` , likewise `scheduler`  to `etcd` too. 
>the reason why the `scheduler`  --> passed info to `apiserver`  -x- not to `etcd`, due to security + nature/design of K8s + distributed systems since the `apiserver` is the brain and mediator between the K8s Components.

7) after storing the information, `etcd`  acknowledges back  -> to `apiserver` 
*(<---)*
8) `apiserver` --> will talk back to `scheduler` - passes the acknowledgement -> to create `pods` at any on of the nodes' `kubelet` to  any one of the relevant worker node, relevant `Pod` acknowledges  back to `apiserver` back that the **Pod Creation process** is going to get initiated. 
*(---->)*
> all these decision has been done here, ON THE CONTROL PLANE NODE.
9) After getting all that info from `Control Plane`'s `api-server` --> `kubelet` service,
*(---watch(bound pod)--->)*
`kubelet` --> will pass command via `crictl` -> `containerd or any cri` 
*(---crictl--->)*
creating all the relevant `PODs`.
10) after all `PODs` has been created, `containerd or any cri` --> will send back the **acknowledgement** to `kubelet`.
(<----)
11) again, `kubelet` --> will pass that acknowledgement info to `apiserver`
*(<---update pod status---)*
12) `apiserver` --> stores that info too in `etcd`
*(---write --->)*
13) `etcd` --> sends back the acknowledgement to `apisever` 
*(<---)*
14) `apiserver` --> will send info to `kubelet` and 
*(---->)*
15) `apiserver` --> Will send and we will be RECEIVING THE CONSOLE OUTPUT THAT THE **PODS HAS BEEN CREATED, FAILED OR PENDING**
16) ALL DONE!
Now we can take care working with the rest as 
```
kubectl get pod -o wide -A
kubectl describe pod
```

