Jobs termination and cleanup - [Doc]

Now will see more about
- Jobs creation process
- what happens under the hood
- Job Execution
- Job Termination
- Job cleanup and more.

Will take a right manifest which a `job` gets successful. 

`hellojob1.yaml`
```Yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: job1
spec:
  template:
    spec:
      containers:
      - name: job1-container
        image: alpine:latest
        command: ["/bin/sh"]
        args: ["-c", "echo Hello from the job1"]
      restartPolicy: Never
```

apply the job,
```sh
kubectl create -f /path/to/hellojob1.yaml
kubectl get jobs,po -o wide
kubectl logs podName
```

1) the jobs get completed 1/1(unless and until there's an error)
2) the pods get 0/1 cause, logically it is a one time exec and just dies after completion. - default behavior of `job` object

**To cleanup these:**
```sh
kubectl delete jobs jobName/orTheManifest
```
you can keep all these resources, if you want to troubleshoot or perform and investigation or sum.

to see like,
- what was up with this job
- what are all the step that has been executed
- what are the after effects and such.
for the administrator's conveniences.

Since the `restartPolicy: never`, if the exec is an error. The Job will be recreated again and again trying to exec the same successfully. 

###### backOffLimit
AGAIN, A NEW POD WILL BE CREATED TO FIX THE SAME. GETS FAILED AND `+1` AND `1` AND `1`. so,
**WHATS THE MAXIMUM?**

will see that by executing a failure command,
```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: job1
spec:
  template:
    spec:
      containers:
      - name: job1-container
        image: alpine:latest
        command: ["/bin/sh"]
        args: ["-c", "ls -l samm"] #which doesn't exist and fails  
      restartPolicy: Never
```
*process: containerCreating -> Error*
after sometime, it stops up to a certain number. **possibly `7`**. The highest maximum. -> known as **BackOffLimit**. and
A job's **backOffLimit** default value is 7. 

`Job will reach the specified backoff limit.`


**WHATS THE MAXIMUM?**
to inspect that,
```sh
kubectl describe job jobName
kubectl get jobs jobName -o yaml
```
and there will be the backOffLimits
and you get more of the same. 

**How to set backOffLimits**? in the manifest itself.
```yaml
spec:
  backoffLimit: 3
  template:
    spec:
      containers:
      ...
```
and that simple. and work it out by creating the same. 

```sh
kubectl get jobs jobName -o yaml
kubectl create jobs jobName -o yaml
kubectl describe jobs jobName -o yaml
```
failed: 4 `n+1) `

###### Suspend
 when we create a `job`, as per the workflow, it immediately proceeds to create a POD with a container in it. 

If you don't want that. I don't want to trigger the POD to run the execution right away. 
To do that, we have to suspend the `job`. 
 
```yaml
spec:
  backoffLimit: 3
  suspend: true
  template:
    spec:
      containers:
      ...
```

create `Job` object,
```sh
kubectl create -f /path/to/jobs.yaml
```

verify,
```sh
kubectl get jobs,po -o wide
kubectl describe job jobName
```
>**`STATUS: Suspended`**, NOT POD has been created yet. 
`Events:
Job suspended by `job-controller`

It just suspended the `job`, since we passed `suspend: true`

OKAY, BUT WHY?
for deployments and such, if we create and run a job before deploying the app. 
IT SIMPLY SPINS THE TASK AND GET SUSPENDED.


to un-suspend: `suspend: false`
```sh
kubectl edit job jobName
```
and modify `suspend` parameter `=false. 

Immediately, triggers the POD right after the edit. 


###### cleanups:
```sh
kubectl delete jobs jobName/orTheManifest
```
this we all know. 

cleanup after every POD execs and it just exists after completion as a trash. IT SIMPLY EXIST IN THE CLUSTER AFTER COMPLETION DOING NOTHING. 

HOW BOUT `deletion` after the `Job` is done. It is possible by with the help of `ttl`- **Time To leave**,  passing the  param to perform cleanUp after seconds, minutes and hours. `ttlSecondsAfterFinished: 10`:
```yaml
spec:
  backoffLimit: 3
  suspend: true
  ttlSecondsAfterFinished: 10
  template:
    spec:
      containers:
      ...
```

FINAL MANIFEST:
```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: job1
spec:
  backoffLimit: 3
  suspend: false
  ttlSecondsAfterFinished: 10 #time to leave
  template:
    spec:
      containers:
      - name: job1-container
        image: alpine:latest
        command: ["/bin/sh"]
        args: ["-c", "echo Hello from the job1"]
      restartPolicy: Never
```

OR to modify and apply just the changes,
```yaml
spec:
  backoffLimit: 3
  suspend: true
  ttlSecondsAfterFinished: 10
  template:
    spec:
      containers:
      ...
```
and
```sh
kubectl replace --force -f /path/to/jobs.yaml
kubectl get jobs,po -o wide 
```

> ===**GETS DELETED AFTER merely 10Seconds of Execution**. AUTOCLEANUP===

![[moss.jpeg]]

---
