K8s workload resource Introduction to Jobs - [Doc]

Running batch operations, scripts, crontab, jobs and such. How to in all these K8s clusters. varies much from what we have been implementing,

In such operational actions, will get started with Jobs:
- What is Jobs?
- Use cases, purpose and applications, 
- all the functionalities, conditions and such. 
> K8s Workloads - ==**Jobs `jobs`**==
##### K8s Workload Resources: **Jobs** `jobs`
- `Jobs` Jobs are workload resource which will ensure one or more pods created and terminate successfully.
- In general, we use `Jobs` to run some batch operations like Backups, Restore etc.,
- **Workflow**: `Jobs` -> POD
- `apiVersion` for `Jobs` Object is `batch/v1`
- `Jobs` can also run multiple pods in parallel
- Once task specified in POD container was successful, **Job** goes to completed status
- **Job** `selector` is optional
- PODs controlled by **Job** object `restartPolicy` should be set to only `Never` or `OnFailure`, not `Always`
- Types of parallel executions Jobs:
1) Non-parallel **jobs**
2) Parallel **jobs** with a fixed completion count
3) Parallel **jobs** with a work queue
- Best Practice is to enable `ttlSecondsAfterFinished: 100` for **Job** to clean up automatically after the TTL value (`.spec.ttlSecondsAfterFinished`) which system will not put pressure on the `kube-apiserver` [stable-v1.23]
- We can suspend the Job as well and start again by `.spec.suspend` value to **true** or **false**
> 1) Note: If a **Job** is suspended, any running POD that don't have status completed will be terminated
> 2) Command:
```sh
kubectl patch job/jobName --type=strategic --patch '{"spec":{"suspend":true}}'
```

##### `Jobs` Jobs are workload resource which will ensure one or more pods created and terminate successfully.
> Ensures one or more PODs either gets created or terminate successfully up and running.

How this Job performing this action? - is via following instructions to perform a specific task. which ensures one or more PODs either gets created or terminate successfully up and running.

WHAT TYPES OR INSTRUCTIONS AND TASKS?
##### In general, we use `Jobs` to run some batch operations like Backups, Restore etc.,
tasks such as taking backups, restores states and all the operational grunt work for our PODs, clusters, or for out applications. 
> Instead of using `initContainers` which have its own limitations, will be using `Jobs` for extensive use cases. 

MOST WE USE ALL THESE FOR **LOGS, BACKUP AND RESTORE**. once a job gets done, POD gets hibernated printing the status as `completed` if job is successful or else, `failed` or `terminated` and we should be troubleshoot them. 
you can verify that using
```sh
kubectl get po -o wide
```

##### **Workflow**: `Jobs` -> POD
Jobs creates PODs. running that specific task.

##### `apiVersion` for `Jobs` Object is `batch/v1`
for jobs, cronjobs, `apiVersion` for `Jobs` Object is `batch/v1`
```yaml
apiVersion: batch/v1
kind: Jobs
```

##### `Jobs` can also run multiple pods in parallel
as the title says, `Jobs` can also run multiple pods in parallel to run, gets done and dusted. 

##### Once task specified in POD container was successful, **Job** goes to completed status
as same as we discussed earlier is that,  once a job gets done, POD gets hibernated printing the status as `completed` if job is successful or else, `failed` or `terminated` and we should be troubleshoot them. 

##### **Job** `selector` is optional
while writing the manifest for running a `Job` object, we can run `selector`, `labeling` but them are all totally optional. nothing happens and works just fine if we fail to mention too. 

##### PODs controlled by **Job** object `restartPolicy` should be set to only `Never` or `OnFailure`, not `Always`
```yaml
restartPolicy: never/onFailure
```
but not `always`, since `jobs` object are supposed not to be actively by nature. if ain't, that is not a `Job` running an instructions, runs if runs, fails if fails. 

##### Types of parallel executions Jobs:
1) Non-parallel **jobs**
2) Parallel **jobs** with a fixed completion count
3) Parallel **jobs** with a work queue
what are the types parallel executions we can do under the `Jobs` object,
4) Non-parallel **jobs** - *default*
5) Parallel **jobs** with a fixed completion count - need PARAMS
6) Parallel **jobs** with a work queue - need PARAMS
will see all these in practice. 

##### Best Practice is to enable `ttlSecondsAfterFinished: 100` for **Job** to clean up automatically after the TTL value (`.spec.ttlSecondsAfterFinished`) which system will not put pressure on the `kube-apiserver` [stable-v1.23]
ALWAYS A BEST PRACTICE TO PERFORM CLEANUPS of the `Jobs`. adds load in the `kube-apiServer` if we fail do cleanup. 
to do these - **enable `ttlSecondsAfterFinished: 100` for Job to clean up automatically after the TTL value (`.spec.ttlSecondsAfterFinished`) which system will not put pressure on the `kube-apiserver`**

default of  `ttlSecondsAfterFinished`: is `100` 

##### We can suspend the Job as well and start again by `.spec.suspend` value to **true** or **false**
We can suspend the Job as well and start again by `.spec.suspend` value to **true** or **false**.

If a **Job** is suspended, any running POD that don't have status completed will be terminated.
eg: `Job` -> `Pod`, is under creation process. meanwhile, you suspend your Job and restart if it fails to create, run or completed status.  to perform that, imperative approach running the command: 
```sh
kubectl batch job/jobName --type=strategic --patch '{"spec":{"suspend":true/false}}'
```

WILL SEE ALL THESE IN PRACTICE.

---