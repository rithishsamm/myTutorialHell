##### Section 5: K8S Replication Controller
1.  Introduction to Replication Controller(Rc)
		Intro RC - [Doc](obsidian://open?vault=tutorialHell&file=Orchestration%2Fk8engineers.com%2FKubernetes-Deep-Dive%2Foffl-raw-docs%2Fkubernetes%20deepdive%2Fsection5-replication-controller%2F1.%20K8s%20Workloads%20-%20Intro%20RC.docx)
2.  Implement RC using declarative approach
		RC using declarative approach - [Doc](obsidian://open?vault=tutorialHell&file=Orchestration%2Fk8engineers.com%2FKubernetes-Deep-Dive%2Foffl-raw-docs%2Fkubernetes%20deepdive%2Fsection5-replication-controller%2F2.%20RC%20using%20declarative%20approach.docx)
3.  RC scale in and scale out
		RC - Scale in & Scale out - [Doc](obsidian://open?vault=tutorialHell&file=Orchestration%2Fk8engineers.com%2FKubernetes-Deep-Dive%2Foffl-raw-docs%2Fkubernetes%20deepdive%2Fsection5-replication-controller%2F3.%20RC%20-%20Scalein%20%26%20Scaleout.docx)
4.  RC and POD label selector
		RC & POD label selector -[Doc](obsidian://open?vault=tutorialHell&file=Orchestration%2Fk8engineers.com%2FKubernetes-Deep-Dive%2Foffl-raw-docs%2Fkubernetes%20deepdive%2Fsection5-replication-controller%2F4.%20RC%20%26%20POD%20label%20selector.docx)
5.  How to delete RC using cascade option
		RC using Cascade option -[Doc](obsidian://open?vault=tutorialHell&file=Orchestration%2Fk8engineers.com%2FKubernetes-Deep-Dive%2Foffl-raw-docs%2Fkubernetes%20deepdive%2Fsection5-replication-controller%2F5.%20RC%20using%20Cascade%20option.docx)
***

#### 1.  Introduction to Replication Controller(Rc)
###### Intro RC - [Doc](obsidian://open?vault=tutorialHell&file=Orchestration%2Fk8engineers.com%2FKubernetes-Deep-Dive%2Foffl-raw-docs%2Fkubernetes%20deepdive%2Fsection5-replication-controller%2F1.%20K8s%20Workloads%20-%20Intro%20RC.docx)

**K8s Workload Resource: Introduction to Replication Controller`rc`:**
So far continuing with the K8s Workload Resources, Will start covering all of these one by one. Starting with **Replication Controller `rc`**
1. It makes sur specified number of PODs (workloads) are running at any given point of time on the cluster
eg: running an app

1. Replication Controller will make sure only specified number of PODs are running and will remove/add if it founds any mismatch
2. `apiVersion`  for the `rc` object is `v1`
3. Workflow: Replication Controller -> POD
4. Its recommend to deploy application on K8s  with minimum workload resource `ReplicationController`, instead of POD.
5. We need to use ReplicaSet, instead of ReplicationController as Deployment Object uses ReplicaSet
6. `rc` will use pod template to create POD with same specifications based on replica count (`.spec.replicas=1`)
7. Scale in and Scaleout of replicas are done using 
```
kubectl scale --replicas=n rc/rcName 
```
9. Only a `.spec.template.metadata.labels` should be equal to `.spec.selector` to handle the PODs by `ReplicationController`
10. Pod Selector,  `.spec.template.metadata.labels` should be equal to `.spec.selector` to handle the PODs by `ReplicationController`
11. If `.spec.selector` is undefined, default it will set to `.spec.template,metadata.labels`
12. In order to delete POD managed under RC, delete RC not the POD. Nothing gets deleted by deleting PODs.
13. We can delete RC without deleting PODs managed by RC 
```
kubeclt delete --cascade=orphan
```
14. PODs controlled by RC can be isolated by changing the labels (to troubleshoot by moving out of the service LoadBalancer)

###### Briefs:
1. **It makes sures that the specified number of PODs (workloads) are running at any given point of time on the cluster.**
 eg: to run apps with `n` of replicas in the backend on different nodes, use `rc`.  

2. **Replication Controller will make sure only specified number of PODs are running and will remove/add if it founds any mismatch**
Maintains the desired state, removes if exceeds, increases if anything gets down. this is performed by `kube-controller-manager`. 
No downtime will occur if any POD gets down since i have multiple PODs running on the side. *which is not possible in standalone pods.*

3. **`apiVersion`  for the `rc` object is `v1`**
in declarative approach of creating `rc`, `apiVersion` for `rc=v1` rc.yaml's
```
apiversion=v1
```

4. **Workflow: Replication Controller -> POD**
Workflow of `rc:` So far, we've been the one who creating the workloads and PODs all on our won manually. All done by you even  the creation, provisioning and managing.

Here, `rc`  takes care of creating and managing PODs. 
always `rc` or workload resources that have `replication` nature to it are much recommended for working with PODs. 
where we can scale in and out declaring actual and desired state. 
which isn't possible in a standalone workload.

That simply it for the `scalabilty` as a factor.

5. **Its recommend to deploy application on K8s with minimum workload resource `ReplicationController`, instead of POD.**
strictly, use the workload resources with the `replication` factor in prod. maintains desired state to keep the apps HA and replicates on multiple nodes in ease. 

6. **use `ReplicaSet`, instead of `ReplicationController` as `Deployment` Object uses `ReplicaSet`**
On the other side, use **`ReplicaSet`**  instead of `replication-controller` **as we use `Deployment` as Object**
which uses `ReplicaSet` to spin the workloads. both are moreover same either in terms of general functionalities or `replication`. BUT WHY? `replicaset` have something called `selector` which ==**selects labels. Way of working with labels by defining and selecting is different.** ==

7. **`rc` will use *pod template* to create POD with same specifications based on replica count (`.spec.replicas=1`)**
where that itself is a feature that `rc` does which replicates also the specifications of PODs based on replica count. if nothing specified under the `spec` section, the default is `.spec.replicas=1`. If need more than one, should define the parameter in the `spec` section `.spec.replicas=1`. 
OK? what is ***pod template***? - it is like **Launch Template** in AWS.
> Every POD will get created based on that template.
> -  how a pod has to be created, all the specs and stuff. 
> - how many containers to create 
> - naming such containers
> - all the images for such containers
> - ports to be exposed for such containers
> - volumes for that workloads
> - and volumeMounts to be mounted on such containers and more

written under the `replica` template. 

 8.`scaling` can be done in ease.  **ScaleIn and Scaleout of replicas are done using** command
```
kubectl scale --replicas=`n` rc/ rcName 
```
to **scale in and out**. 

9. restartPolicy for `rc`
 Only a `.spec.template.spec.restartPolicy = always` is allowed and its default* if not defined,
Restart policy in `rc` is as same as the rest which is *`always`*, *`onFailure`* and never to be written on POD template not under spec section of the `rc`,
-- `.spec.template.spec.restartPolicy = always`

11. Identifying PODs with **labels**: (no selector but in `rs`)
Pod Selector,  `.spec.template.metadata.labels` should be equal to `.spec.selector` to handle the PODs by `ReplicationController`.
	Since all of our PODs are getting created by `replication-controller`, how it identifies a POD?  
PODs will be created with the labels all defined and that will be the probable identification of the POD for the `rc`. That's how to identify a POD using **labels**. 

How to define a label for a POD in template - `spec.template.sepc.restartPolicy`
How to select a POD with labels. - `spec.selector`.
HOW TO ASSIGN A LABEL FOR A POD?
```
spec: 
  template:
    metadata.labels: 
```
should selectable, identify and controlled for `rc`. 

12.  **If `.spec.selector` is undefined, default it will set to the labels given there `.spec.template,metadata.labels`**
 If no `.spec.selector is defined`, what are all the labels has been defined in the `.spec.template.metadata.labels` will be taken in action for POD identification - labels.

13. **In order to delete POD managed under `rc`, delete `rc` not the POD. Nothing gets deleted by deleting PODs.**
```
kubectl delete rc rcName
```
or to scale in by restricting the replica count.

14) ==**We can delete RC without deleting PODs managed by RC**.==
is possible by passing this command, **HELPS IN SPECIAL CA**SES.
```
kubeclt delete --cascade=orphan
```
if you execute this with `rc/rcname`, all the PODs will be available, but not the `rc`.
> WHY? can create new `replication-controller` using the same old pods. i**f any misconfiguration or forget to add a parameter and has been spinning up there for a while, where you can delete `rc` and recreate but not the pods, edit and relaunch the same.**

15. **PODs controlled by RC can be isolated by changing the labels (to troubleshoot by moving out of the service LoadBalancer)**
 PODs which are controlled by `rc` can be isolated by changing the labels. 
 eg: `rc` setup that exist which them PODs can be identified with labels. On the other side, where 
 - if I'll be creating standalone PODs and declaring the same labels, THAT WILL ALSO BE CONTROLLED BY `rc` too. 
- Meanwhile, If I be removing a label of a POD which is controlled by `rc`, the POD gets isolated and no longer will be controlled by `rc`
 SO, SHOULD BE CAREFUL WITH DEFINING LABELS. These cases will be helpful for troubleshooting the PODs, Containers, Objects, Batch, Components and more. 

where you can isolate them out of `rc` by removing the label. After all the process gets done. then, you can add the labels which will get controlled and maintained under `rc` too. 
***

# 2) Demo! Implement `RC` using declarative approach?

DEPLOYNG REALTIME `RC` ON MULTIPLE NODES IRL:

 