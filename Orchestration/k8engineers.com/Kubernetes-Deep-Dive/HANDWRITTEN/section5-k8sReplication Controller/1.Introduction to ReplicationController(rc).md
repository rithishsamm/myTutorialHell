- Intro RC - Doc
##### Section 5: K8S Replication Controller
#### 1.  Introduction to Replication Controller(Rc)
###### Intro RC - [Doc](obsidian://open?vault=tutorialHell&file=Orchestration%2Fk8engineers.com%2FKubernetes-Deep-Dive%2Foffl-raw-docs%2Fkubernetes%20deepdive%2Fsection5-replication-controller%2F1.%20K8s%20Workloads%20-%20Intro%20RC.docx)

**K8s Workload Resource: Introduction to Replication Controller (rc):**

So far continuing with the K8s Workload Resources, Will start covering all of these one by one. Starting with **Replication Controller (rc)**

1. It makes sur specified number of PODs (workloads) are running at any given point of time on the cluster
2. Replication Controller will make sure only specified number of PODs are running and will remove/add if it founds any mismatch
3. `apiVersion`  for the `rc` object is `v1`
4. Workflow: Replication Controller -> POD
5. Its recommend to deploy application on K8s  with minimum workload resource `ReplicationController`, instead of POD.
6. We need to use ReplicaSet, instead of ReplicationController as Deployment Object uses ReplicaSet
7. `rc` will use pod template to create POD with same specifications based on replica count (`.spec.replicas=1`)
8. Scalein and Scaleout of replicas are done using 
```
kubectl scale --replicas=n rc/rcName 
```
9. Only a `.spec.template.metadata.labels` should be equal to `.spec.selector` to handle the PODs by `ReplicationController`
10. Pod Selector,  `.spec.template.metadata.labels` should be equal to `.spec.selector` to handle the PODs by `ReplicationController`
11. If `.spec.selector` is undefined, default it will set to `.spec.template,metadata.labels`
12. In order to delete POD managed under RC, delete RC not the POD. Nothing gets deleted by deleting PODs.
13. We can delete RC without deleting PODs managed by RC 
```
kubeclt delete --cascade=orphan
```
14. PODs controlled by RC can be isolated by changing the labels (to troubleshoot by moving out of the service LoadBalancer)

###### Briefs:
1. **It makes sures that the specified number of PODs (workloads) are running at any given point of time on the cluster.**
like, I want to run an application on K8s Cluster.
In `rc`, you can spin n number of PODs to run application by declaring PODs on-demand if i be specifying some number of PODs to be exist in the K8s Cluster. 
No downtime will occur if any POD gets down since i have multiple PODs running on the side. *which is not possible in standalone pods.*  

2. **Replication Controller will make sure only specified number of PODs are running and will remove/add if it founds any mismatch**
eg:  
if i declare `replica=3`, 
deletes if PODs are more than 3,
creates if PODs are less than 3.
to match the desired state with the actual state.
> **This has been possible with the `kube-controller-manager`**

3. **`apiVersion`  for the `rc` object is `v1`**
as we all know what this is. by writing a manifest for `rc`, 
The `apiVersion` for `replicationController` is `v1`. while we try creating things all the same in a declarative approach.
```
apiversion=v1
```

4. **Workflow: Replication Controller -> POD**
Replication Controller creates PODs. 
Here, the in charge of such PODs is not you but `rc` which takes care of creating and managing such PODs. So, better deploy `rc` rather than POD. why, cause of `Replication` factor where we can scale in and out declaring actual and desired state. 
which isn't possible in a standalone workload.
> Not you. If we create PODs those will be standalone PODs. here, we try to spin PODs using `rc`.  

That simply it for the `scalabilty` as a factor.


5. **Its recommend to deploy application on K8s with minimum workload resource `ReplicationController`, instead of POD.**
 as we discuss earlier, the subject tells the same. for the `replication` factor. 
> `Replication` factor where we can scale in and out declaring actual and desired state. 

6. **We need to use ReplicaSet, instead of ReplicationController as Deployment Object uses ReplicaSet**
On the other side, we need to use **`ReplicaSet`**  instead of `replication-controller` **as we use Deployment as Object** which uses ReplicaSet to create such. We should use if `replication` matters on a larger scale.  both are moreover same either in terms of general functionalities or `replication`. BUT WHY? `replicaset` have something called `selector` which selects labels. Way of working with labels by defining and selecting is different. 

7. **`rc` will use *pod template* to create POD with same specifications based on replica count (`.spec.replicas=1`)**
where that itself is a feature that `rc` does which replicates also the specifications of PODs based on replica count. if nothing specified under the `spec` section, the default is `.spec.replicas=1`. If need more than one, should define the parameter in the `spec` section `.spec.replicas=1`. 
OK? what is ***pod template***? - it is like **Launch Template** in AWS.
> Every POD will get created based on that template.
> -  how a pod has to be created, all the specs and stuff. 
> - how many containers to create 
> - naming such containers
> - all the images for such containers
> - ports to be exposed for such containers
> - volumes for that workloads
> - and volumeMounts to be mounted on such containers and more

8. **ScaleIn and Scaleout of replicas are done using** command
```
kubectl scale --replicas=n rc/ rcName 
```

9. **Only a `.spec.template.spec.restartPolicy = always` is allowed and its default if not defined**
Restart policy in `rc` is as same as the rest which is always, onFailure and never to be written on POD template not under spec section of the `rc`,
-- `.spec.template.spec.restartPolicy = always`

11. **Pod Selector,  `.spec.template.metadata.labels` should be equal to `.spec.selector` to handle the PODs by `ReplicationController`**
	Since all of our PODs are getting created by `replication-controller`, how it identifies a POD?  
PODs will be created with the labels all defined and that will be the probable identification of the POD for the `rc`. That's how to identify a POD using labels. 

How to define a label for a POD in template - `spec.template.sepc.restartPolicy`
How to select a POD with labels. - `spec.selector`.
HOW TO ASSIGN A LABEL FOR A POD?
```
spec: 
  template:
    metadata: 
      - labels
```
should selectable, identify and controlled for `rc`. 

12.  **If `.spec.selector` is undefined, default it will set to `.spec.template,metadata.labels`**
 If no `.spec.selector is defined`, what are all the labels has been defined in the `.spec.template.metadata.labels` will be taken in action for POD identification - labels.

13. **In order to delete POD managed under RC, delete RC not the POD. Nothing gets deleted by deleting PODs.**
```
kubectl delete rc rcName
```
or to scale in by restricting the replica count.

14. **We can delete RC without deleting PODs managed by RC**.
is possible by passing this command, **HELPS IN SPECIAL CA**SES.
```
kubeclt delete --cascade=orphan
```
if you execute this with `rc/rcname`, all the PODs will be available, but not the `rc`.
> WHY? can create new `replication-controller` using the same old pods. if any misconfiguration or forget to add a parameter and has been spinning up there for a while, where you can delete `rc` and recreate but not the pods, edit and relaunch the same.

15. **PODs controlled by RC can be isolated by changing the labels (to troubleshoot by moving out of the service LoadBalancer)**
 PO