1.  Introduction to ReplicaSet(Rs)
		 K8s Workloads - Replica Set - [Doc]
2. Implement RS using declarative approach
		RS creation in Declarative approach - [Doc]
3.  RS scale in and scale out
4.  RS and POD label selector(match Labels)
		RS - match Labels - [Doc]
5. RS and POD label selector (match Expressions)
6.  How to delete RS using cascade option
		 RS - Cascade Option - [Doc]

---
# 1) Introduction to ReplicaSet (rs)

==**ReplicaSet ensures that a specified number of pod replicas are running at any given time.**==

Will see our next work: **ReplicaSet** - `rs`
Lastly, we have seen about the Replication Controller `rc` what we do with it, its purpose, capabilities, limitations and especially, how the concept of `replication` works. 

ReplicaSet `rs` is more or less similar to `rc`. The major difference between these - **`selectors and labels`**

More theory in brief about the `replicaset`, its use cases and its applications.  

##### K8s Workload Resources: ReplicaSet `rs`
- It make sure that specified number of PODs (workload) are running at any given point of time on the Cluster 
- Deployment Object uses ReplicaSet `rs` to manage POD replicas
-  `apiVersion` for `ReplicaSet` Object is `apps/v1`
- Workflow: `ReplicaSet` -> POD
- It is recommended to use `Deployment` instead of `ReplicaSet` (unless we need to manually upgrade the application)
- RS will use `podTemplate` to create POD with the same specifications based on replica count (`spec.replicas=1`)
- Make sure standalone PODs do not match labels with `ReplicaSet` and `ReplicationController` as well 
- In the `ReplicaSet` - `.spec.template.metadata.labels` must match `.spec.selector`, or it will be rejected by the API
- In order to delete POD managed under `RS`, delete `RS` not POD
- We can delete RS without deleting PODs managed by RS 
```sh
kubectl delete -cascade=orphan
```
- PODs controlled by RS can be isolated by changing the labels (to troubleshoot by moving out of service LoadBalancer)
- `ScaleIn` and `ScaleOut` of `replicas` are done using 
```sh
kubectl scale --replicas=n rs/rsName
```
- `RS`'s `selector` supports two parameters to define labels `matchLabels` and `matchExpressions`
- `matchExpressions` has key, operator and values parameters

**In brief:** 
ReplicaSet `rs` is more or less similar to `rc`. The major difference between these - **`selectors and labels`**. will see all that differences and the applications where it has to be used appropriately,

###### 1) It make sure that specified number of PODs (workload) are running at any given point of time on the Cluster 
as same as `rc`,  eg: to run apps with `n` of replicas in the backend on different nodes, can use `rs`as well as `rc`.

ensures desired number that is specified to run the PODs in the replicas. maintaining desired state = actual state 

###### 2) Deployment Object uses ReplicaSet `rs` to manage POD replicas
just like `rs` uses `rc` under the hood for its functionalities especially Replication to manage PODs/Replicas. 
**`deployment` which is also a workload resource that will cover later - uses `rs` under the hood for its functionalities especially Replication to manage PODs/Replicas.**

- ###### `apiVersion` for `ReplicaSet` Object is `apps/v1`
in declarative approach of creating `rs`, `apiVersion` for `rs=app/v1` rc.yaml's
```yaml
apiversion: apps/v1
kind: ReplicaSet
```

- ###### Workflow: `ReplicaSet` -> POD
==**Instead of we taking care of the POD creation process, the workload resource that uses replication concept creates the PODs. which is you create `rc` -> `ReplicaSet` -> creates the POD**==

Workflow of `rs`, So far, we've been the one who creating the workloads and PODs all on our won manually. All done by you even  the creation, provisioning and managing.

Here, `rs`  takes care of creating and managing PODs. 
always `rs` or workload resources that have `replication` nature to it are much recommended for working with PODs. 
where we can scale in and out declaring actual and desired state. 
which isn't possible in a standalone workload.

That simply it for the `scalabilty` as a factor.

- ###### It is recommended to use `Deployment` instead of `ReplicaSet` (unless we need to manually upgrade the application)

==**`Deployment` >>> `rs`.**==

Deployment:
- embraces `Replication` concept/functionality more than `rs` and `rc` 
- good for `Roll back`, `Roll out` for upgrading and downgrading application
- minimal and default baseline option to approach for creating PODs in ease with `replication`
SO, ALWAYS DEPLOY APPLICATION USING `DEPLOYMENT`

- ###### `RS` will use `podTemplate` to create POD with the same specifications based on replica count (`spec.replicas=1`)
**==EXACTLY AS SAME AS `RC`,==**

where that itself is a feature that `rS` does which replicates also the specifications of PODs based on replica count. if nothing specified under the `spec` section, the default is `.spec.replicas=1`. If need more than one, should define the parameter in the `spec` section `.spec.replicas=1`. 
OK? what is ***pod template***? - it is like **Launch Template** in AWS.
> Every POD will get created based on that template.
> -  how a pod has to be created, all the specs and stuff. 
> - how many containers to create 
> - naming such containers
> - all the images for such containers
> - ports to be exposed for such containers
> - volumes for that workloads
> - and volumeMounts to be mounted on such containers and more
written under the `replica` template. 


- ###### Make sure standalone PODs do not match labels with `ReplicaSet` and `ReplicationController` as well 
which means, whenever we create `rs` or `rc`, we specify labels has to identical/match with the POD labels.

Make sure that the standalone PODs have not the same. 

What if? : That gets controlled by `rs` too. if conflicts the application, its over. if not, Its okay to use. SO, MUST BE CAREFUL WHEN ASSIGNING LABELS TO THE PODs and to the WORKLOAD RESOURCES. 


- ###### In the `ReplicaSet` - `.spec.template.metadata.labels` must match `.spec.selector`, or it will be rejected by the API
==**Pod TemplateLabels = `rs` Selector Labels**==, or else, it will be rejected by the `apiServer` and NO PODs WILL GET CREATED.


- ###### In order to delete POD managed under `RS`, delete `RS` not POD
as same as we saw earlier with all the Workload Resources that supports Replication concept. 

no use of deleting PODs, will get recreated. to delete the PODs managed by `rs`, delete `rs`.

- ###### We can delete RS without deleting PODs managed by RS 
```sh
kubectl delete -cascade=orphan
```
vice versa + as we saw earlier with the `rc`


- ###### PODs controlled by `RS` can be isolated by changing the labels (to troubleshoot by moving out of service LoadBalancer)
vice versa + as we saw earlier with the `rc` too. seperate the PODs and isolate it by changing labels -> troubleshoot and do all the patchworks, after completing -> reassign the same labels to PODs for the `rs` to get adapt to it.


- ###### `ScaleIn` and `ScaleOut` of `replicas` are done using 
```sh
kubectl scale --replicas=n rs/rsName
```
vice versa + as we saw earlier with the `rc` too.


###### `RS`'s `selector` supports two parameters to define labels -> `matchLabels` and `matchExpressions`
- `matchLabels` - typical labels that we use 
- `matchExpressions` - same + add can add logic to identify the resource, 

- ###### `matchExpressions` has key, operator and values parameters
that logic  to identify the resource is nothing but parameters - `key, operator and Values`


---
# 2) Implement RS using declarative approach
**RS creation in Declarative approach - [Doc]**



---
# 3) RS scale in and scale out



---
# 4) Demo: RS and POD Label selector (match Labels)

Understanding `matchLabels` for ReplicaSet (NOT `rc` TO GET A BRIEF UNDERSTANDING ABOUT THE WORKINGS OF LABELS FOR `rc` AND `rs`): 

Since we saw about Labels before, if u refer the manifest:
```yaml
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: nginx-rs
  labels:
    app: nginx-app
    env: prod
    release: v1.0
  
spec:
  replicas: 3
  # selector:
  #   matchLabels:
  #    app: nginx-rc
  #    env: prod
  #    release: v1.0
  template:
    metadata:
      name: nginx-rs
      labels:
        app: nginx-app
        env: prod
        release: v1.0
  
    spec:
      containers:
      - name: write-app
        image: alpine
        command: ["/bin/sh"]
        args: ["-c", "while true; do date >> /var/log/index.html; sleep 10; done"]
        volumeMounts:
        - name: rc-shared-volume
          mountPath: /var/log
      - name: server-app
        image: nginx:latest
        ports:
        - containerPort: 80
        volumeMounts:
        - name: rc-shared-volume
          mountPath: /usr/share/nginx/html
  
      volumes:
      - name: rc-shared-volume
        emptyDir: {}
```

here, if no `matchLabels` section declared under the spec section of `rc` (not the containers) the labels from the template section's metadata labels gets taken into consideration and get assigned to the `rc` as labels for the selector to identify:

**What happens to the `rs`?**
if we apply the manifest, error can be seen.
```
The ReplicaSet "nginx-rs" is invalid:
* spec.selector: Required value
* spec.template.metadata.labels: Invalid value: map[string]string{"app":"nginx-app", "env":"prod", "release":"v1.0"}: `selector` does not match template `labels`
```
Throwing this error. Since, we didn't write any selector, it couldn't pass the manifest and deploy the application.

>This isn't `rc` that don't mind labels. 
>Selectors matters and mandatory for `rs` for it to identify the resources. 

WITHOUT WRITING A SELECTOR, YOU CANNOT DEPLOY `rs` in K8s.

Since, there is none here, `rs` couldn't get applied.

> If `rc`, we didn't write any selector and though it gets applied and the selector will be adapted by the labels that are given under the template section. AND THIS IS NOT THE CASE FOR `rs`

`rs-multicontainer+matchLabels.yaml`
```yaml
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: nginx-rs
  labels:
    app: nginx-app
    env: prod
    release: v1.0
  
spec:
  replicas: 3
  selector:
    matchLabels:
     app: nginx-app
     env: prod
     release: v1.0
     
  template:
    metadata:
      name: nginx-rs
      labels:
        app: nginx-app
        env: prod
        release: v1.0

    spec:
      containers:
      - name: write-app
        image: alpine
        command: ["/bin/sh"]
        args: ["-c", "while true; do date >> /var/log/index.html; sleep 10; done"]
        volumeMounts:
        - name: rc-shared-volume
          mountPath: /var/log

      - name: server-app
        image: nginx:latest
        ports:
        - containerPort: 80
        volumeMounts:
        - name: rc-shared-volume
          mountPath: /usr/share/nginx/html

      volumes:
      - name: rc-shared-volume
        emptyDir: {}
```

this gets applied in ease. ++ those labels has to match expressions in both the selector and in the metadata, - to match the labels in the `spec.template.metadata.labels`.
- The `selector.matchLabels` determines which Pods the ReplicaSet manages.
- The `spec.template.metadata.labels` defines the labels assigned to Pods created by the ReplicaSet.
- These two must align for the ReplicaSet to manage its Pods properly.

Label mismatch - PODs will not be controlled by the `rs`

Apply the `rs` and verify the same.
```
kubectl get rs -o wide
kubectl get po -o wide --show-labels
```

Let play around by removing one of the label of `rs`, to do that,  run the same and pick one of the PODs Label: or simply `kubectl edit rs/rsName` to perform the same.

```
kubectl label pods PodName app-
```
will give the output of `POD unlabeled`

AND,
```
kubectl get po -o wide --show-labels
```
now, you can able to see that the 
- unlabeled POD gets isolated, out of `rs`'s control to be orphaned.
- a new POD gets created  with the same labels.

WHY? if you want to do some patch, troubleshooting, run jobs inside the Container or such. But to perform the same outside a circle, isolate it by removing any one of the table and perform the same on a POD.

Delete, if needed. or bring back the same POD to the `rs`, after adding, the last one gets removed. Having a POD in isolation forever is of no use. To add back
```
kubectl label pods isolatedPodName app=label
```
all will be back to default by old one getting associated with the `rs` and one of the least qualified POD gets terminated. 

> **THIS IS HOW `matchLabels` works for `rs`**

Later, we will see in brief about a similar concept name `matchedExpressions`

> [!NOTE]  ##### FINAL file - demo manifest of a multicontainer `replicationcontroller`.  RC - MANIFEST
> ###### multicontainer-rc.yaml.yaml
> ```yaml
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: nginx-rs
  labels:
    app: nginx-app
    env: prod
    release: v1.0
>
spec:
  replicas: 3
  selector:
    matchLabels:
     app: nginx-app
     env: prod
     release: v1.0
>
 template:
    metadata:
      name: nginx-rs
      labels:
        app: nginx-app
        env: prod
        release: v1.0
>
 spec:
      containers:
      - name: write-app
        image: alpine
        command: ["/bin/sh"]
        args: ["-c", "while true; do date >> /var/log/index.html; sleep 10; done"]
        volumeMounts:
        - name: rc-shared-volume
          mountPath: /var/log
>
      - name: server-app
        image: nginx:latest
        ports:
        - containerPort: 80
        volumeMounts:
        - name: rc-shared-volume
          mountPath: /usr/share/nginx/html
  >volumes:
      - name: rc-shared-volume
        emptyDir: {}

---

# 5) Demo: RS and POD Label selector (`matchExpressions`)

Understanding **ReplicaSet Selector: `matchExpressions`** 
-- for ReplicaSet (NOT `rc` TO GET A BRIEF UNDERSTANDING ABOUT THE WORKINGS OF LABELS FOR `rc` AND `rs`): 

So far, we have seen about the `matchLabels` and how to write it for `rs`. Now `matchExpressions`

For `matchExpressions`, There are three parameters to define. 
- Key 
- Operator
- Values
These are the three major parameter factors for defining `matchExpressions` for `rs`.

| Key                                               | Operator                                      | Values                                                                                         |
| ------------------------------------------------- | --------------------------------------------- | ---------------------------------------------------------------------------------------------- |
| `key_name`<br>key- just a variable like any other | `In`<br>`NotIn`<br>`Exist`<br>`DoesNotExists` | `value1`<br>`value2`<br>what one or more values you would like to store under a particular key |
Here, 
- When you right a key, you will 













