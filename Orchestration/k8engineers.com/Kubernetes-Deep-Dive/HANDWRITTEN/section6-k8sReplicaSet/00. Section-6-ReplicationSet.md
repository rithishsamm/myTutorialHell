1.  Introduction to ReplicaSet(Rs)
		 K8s Workloads - Replica Set - [Doc]
2. Implement RS using declarative approach
		RS creation in Declarative approach - [Doc]
3.  RS scale in and scale out
4.  RS and POD label selector(match Labels)
		RS - match Labels - [Doc]
5. RS and POD label selector (match Expressions)
6.  How to delete RS using cascade option
		 RS - Cascade Option - [Doc]

---
# 1) Introduction to ReplicaSet (`rs`)

==**ReplicaSet ensures that a specified number of pod replicas are running at any given time.**==

Will see our next work: **ReplicaSet** - `rs`
Lastly, we have seen about the Replication Controller `rc` what we do with it, its purpose, capabilities, limitations and especially, how the concept of `replication` works. 

ReplicaSet `rs` is more or less similar to `rc`. The major difference between these - **`selectors and labels`**

More theory in brief about the `replicaset`, its use cases and its applications.  

##### K8s Workload Resources: ReplicaSet `rs`
- It make sure that specified number of PODs (workload) are running at any given point of time on the Cluster 
- Deployment Object uses ReplicaSet `rs` to manage POD replicas
-  `apiVersion` for `ReplicaSet` Object is `apps/v1`
- Workflow: `ReplicaSet` -> POD
- It is recommended to use `Deployment` instead of `ReplicaSet` (unless we need to manually upgrade the application)
- RS will use `podTemplate` to create POD with the same specifications based on replica count (`spec.replicas=1`)
- Make sure standalone PODs do not match labels with `ReplicaSet` and `ReplicationController` as well 
- In the `ReplicaSet` - `.spec.template.metadata.labels` must match `.spec.selector`, or it will be rejected by the API
- In order to delete POD managed under `RS`, delete `RS` not POD
- We can delete RS without deleting PODs managed by RS 
```sh
kubectl delete -cascade=orphan
```
- PODs controlled by RS can be isolated by changing the labels (to troubleshoot by moving out of service LoadBalancer)
- `ScaleIn` and `ScaleOut` of `replicas` are done using 
```sh
kubectl scale --replicas=n rs/rsName
```
- `RS`'s `selector` supports two parameters to define labels `matchLabels` and `matchExpressions`
- `matchExpressions` has key, operator and values parameters

**In brief:** 
ReplicaSet `rs` is more or less similar to `rc`. The major difference between these - **`selectors and labels`**. will see all that differences and the applications where it has to be used appropriately,

###### 1) It make sure that specified number of PODs (workload) are running at any given point of time on the Cluster 
as same as `rc`,  eg: to run apps with `n` of replicas in the backend on different nodes, can use `rs`as well as `rc`.

ensures desired number that is specified to run the PODs in the replicas. maintaining desired state = actual state 

###### 2) Deployment Object uses ReplicaSet `rs` to manage POD replicas
just like `rs` uses `rc` under the hood for its functionalities especially Replication to manage PODs/Replicas. 
**`deployment` which is also a workload resource that will cover later - uses `rs` under the hood for its functionalities especially Replication to manage PODs/Replicas.**

###### 3) `apiVersion` for `ReplicaSet` Object is `apps/v1`
in declarative approach of creating `rs`, `apiVersion` for `rs=app/v1` rc.yaml's
```yaml
apiversion: apps/v1
kind: ReplicaSet
```

###### 4) Workflow: `ReplicaSet` -> POD
==**Instead of we taking care of the POD creation process, the workload resource that uses replication concept creates the PODs. which is you create `rc` -> `ReplicaSet` -> creates the POD**==

Workflow of `rs`, So far, we've been the one who creating the workloads and PODs all on our won manually. All done by you even  the creation, provisioning and managing.

Here, `rs`  takes care of creating and managing PODs. 
always `rs` or workload resources that have `replication` nature to it are much recommended for working with PODs. 
where we can scale in and out declaring actual and desired state. 
which isn't possible in a standalone workload.

That simply it for the `scalabilty` as a factor.

###### 5) It is recommended to use `Deployment` instead of `ReplicaSet` (unless we need to manually upgrade the application)

==**`Deployment` >>> `rs`.**==
**Deployment:**
- embraces `Replication` concept/functionality more than `rs` and `rc` 
- good for `Roll back`, `Roll out` for upgrading and downgrading application
- minimal and default baseline option to approach for creating PODs in ease with `replication`
SO, ALWAYS DEPLOY APPLICATION USING `DEPLOYMENT`

###### 6) `RS` will use `podTemplate` to create POD with the same specifications based on replica count (`spec.replicas=1`)
**==EXACTLY AS SAME AS `RC`,==**

where that itself is a feature that `rS` does which replicates also the specifications of PODs based on replica count. if nothing specified under the `spec` section, the default is `.spec.replicas=1`. If need more than one, should define the parameter in the `spec` section `.spec.replicas=1`. 
OK? what is ***pod template***? - it is like **Launch Template** in AWS.
> Every POD will get created based on that template.
> -  how a pod has to be created, all the specs and stuff. 
> - how many containers to create 
> - naming such containers
> - all the images for such containers
> - ports to be exposed for such containers
> - volumes for that workloads
> - and volumeMounts to be mounted on such containers and more
written under the `replica` template. 

###### 7) Make sure standalone PODs do not match labels with `ReplicaSet` and `ReplicationController` as well 
which means, whenever we create `rs` or `rc`, we specify labels has to identical/match with the POD labels.

Make sure that the standalone PODs have not the same. 

What if? : That gets controlled by `rs` too. if conflicts the application, its over. if not, Its okay to use. SO, MUST BE CAREFUL WHEN ASSIGNING LABELS TO THE PODs and to the WORKLOAD RESOURCES. 


###### 8) In the `ReplicaSet` - `.spec.template.metadata.labels` must match `.spec.selector`, or it will be rejected by the API
==**Pod TemplateLabels = `rs` Selector Labels**==, or else, it will be rejected by the `apiServer` and NO PODs WILL GET CREATED.


###### 9) In order to delete POD managed under `RS`, delete `RS` not POD
as same as we saw earlier with all the Workload Resources that supports Replication concept. 

no use of deleting PODs, will get recreated. to delete the PODs managed by `rs`, delete `rs`.

###### 10) We can delete RS without deleting PODs managed by RS 
```sh
kubectl delete -cascade=orphan
```
vice versa + as we saw earlier with the `rc`


###### 11) PODs controlled by `RS` can be isolated by changing the labels (to troubleshoot by moving out of service LoadBalancer)
vice versa + as we saw earlier with the `rc` too. seperate the PODs and isolate it by changing labels -> troubleshoot and do all the patchworks, after completing -> reassign the same labels to PODs for the `rs` to get adapt to it.

###### 12) `ScaleIn` and `ScaleOut` of `replicas` are done using 
```sh
kubectl scale --replicas=n rs/rsName
```
vice versa + as we saw earlier with the `rc` too.

###### 13) `RS`'s `selector` supports two parameters to define labels -> `matchLabels` and `matchExpressions`
- `matchLabels` - typical labels that we use 
- `matchExpressions` - same + add can add logic to identify the resource, 

###### 14) `matchExpressions` has key, operator and values parameters
that logic  to identify the resource is nothing but parameters - `key, operator and Values`


---
# 2) Implement RS using declarative approach
**RS creation in Declarative approach - [Doc]**

Practical on Implementing **`rs`** in declarative way and tinkering with `scalein` and `scaleout`.

```sh
mkdir rs #handling rs's yaml manifests
cd rs
touch rs-multicontainer.yaml
```

to verify api-resources to find proper naming conventions for the manifest:
```sh
kubectl api-resources | grep replicaset
```

> !IMP NOTE: Manifest of `rs` and `rc` are very very similar, but the only major difference is working of `selectors` in `rs` which is heavily work with `matchLabels` and `matchExpressions`, not the Pod Template-label but the workload resource's label. 

Now will see just selector labels, then
- matchLabels, 
- matchExpressions
apart from this `selectors` and `labels`, all the boilerplate (the `apiVersion`, `kind`, `metadata`, `spec` of `rs` and such) and the rest of the parameters are just same (such as PodTemplate, `spec` of containers, `metadata`, POD's `Labels`, `volumes`, mounts and such). 

`rs-multicontainer.yaml`
```yaml
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: nginx-rs
  labels:
    app: nginx-app
    env: prod
    release: v1.0

spec:
  replicas: 3
  selector:
    matchLabels:
     app: nginx-app
     env: prod
     release: v1.0
  
  template:
    metadata:
      name: nginx-rs
      labels:
        app: nginx-app
        env: prod
        release: v1.0

    spec:
      containers:
      - name: write-app
        image: alpine
        command: ["/bin/sh"]
        args: ["-c", "while true; do date >> /var/log/index.html; sleep 10; done"]
        volumeMounts:
        - name: rc-shared-volume
          mountPath: /var/log
      - name: server-app
        image: nginx:latest
        ports:
        - containerPort: 80
        volumeMounts:
        - name: rc-shared-volume
          mountPath: /usr/share/nginx/html

      volumes:
      - name: rc-shared-volume
        emptyDir: {}
```
the same labels has to be in the PODs too! will apply this manifest and create `rs` workload resource.

```sh
kubectl create -f /path/to/rsManifest.yaml
```
schema validation will get passed. if not, recheck the manifest. Now will verify the status of the workload resource `rs`.

```sh
kubectl get rs -o wide
kubectl get po -o wide
```
All the `rc` and `po` gets created. 

to check the labels of these PODs. 
```sh
kubectl get pod -o wide --show-labels
```
can see what are all the labels that are assigned to the PodTemplate. With this,

WE HAVE SUCCESSFULLY DEPLOYED OUR APPLICATION BY USING `rs`.

and the rest of the functionalities as follows. especially, all the `replication` stuff too.

if you delete PODs, by passing
```sh
kubectl delete po podName
```
none gets deleted due to `replication` to make the application highly available, simply recreates a new pod. maintaining and keep matching the desired state = actual state.

To delete a resource, always delete the parent object = (`rc`) not the child (`PODs`) :). deletes `rc` and the `Pods`.
```sh
kubectl delete -f rs/Path/to/rsManifest.yaml
```

- here, in order to delete PODs. delete `rs` not the PODs. its of no use if u do so. none gets deleted too.
- In order to delete PODs without `rs`,  declare the replica count to 0. no PODs will be there. 
- In order to keep the PODs but to delete the `rs`, use cascade,
```sh
kubectl delete -cascade=orphan
```


---
# 3) Demo: RS scalein and scaleout    

Will dig deep into the `scalein` and `scaleout` in `rs`
if u failed to or write/declare any `replicas` parameter here. create only `1` since it is default.
```yaml
spec:
  #replicas: 1
  selector:
    matchLabels:
     app: nginx-app
     env: prod
     release: v1.0
```

`#replicas=n` -> No of Pods
```sh
kubectl create -f /path/to/rsManifest
kubectl get rs -o wide
kubectl get po -o wide
```

**to scaleup the pods** and verify
```sh
kubectl scale --replicas=3 rs/rsName
kubectl get po -o wide
```

same for the **scale Down**,
```sh
kubectl scale --replicas=1 rs/rsName
kubectl get po -o wide
```
will shows, terminating. The Pod which gets terminated is picked to be terminated based on multiple criteria such as resource availability, age and such.

**TO MAINTAIN HIGH AVAILABILITY!**

---
# 4) Demo: RS and POD Label selector (match Labels)

Understanding `matchLabels` for ReplicaSet + `matchExpressions` next following by:

(TO GET A BRIEF UNDERSTANDING ABOUT THE WORKINGS OF LABELS FOR  `rs` when we worked with `rs` likewise): 

Since we saw about Labels before in `rc`, 

> [!NOTE] Key Difference
> If no selector is written or not in the `rc`, there wont be any problem
==If  no selector and no Labels are written are present in the `rs`, the manifest wont accept and doesn't gets schema validated.==
**WITHOUT WRITING A SELECTOR, YOU CANNOT DEPLOY A REPLICASET!**
++
==The PodTemplate has to be identical too. In order to control the PODs using `ReplicaSet`==


```yaml
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: nginx-rs
  labels:
    app: nginx-app
    env: prod
    release: v1.0
  
spec:
  replicas: 3
  # selector:
  #   matchLabels:
  #    app: nginx-rc
  #    env: prod
  #    release: v1.0
  template:
    metadata:
      name: nginx-rs
      labels:
        app: nginx-app
        env: prod
        release: v1.0
  
    spec:
      containers:
      - name: write-app
        image: alpine
        command: ["/bin/sh"]
        args: ["-c", "while true; do date >> /var/log/index.html; sleep 10; done"]
        volumeMounts:
        - name: rc-shared-volume
          mountPath: /var/log
      - name: server-app
        image: nginx:latest
        ports:
        - containerPort: 80
        volumeMounts:
        - name: rc-shared-volume
          mountPath: /usr/share/nginx/html
  
      volumes:
      - name: rc-shared-volume
        emptyDir: {}
```
==Since we have not written the `selector`, this manifest couldn't get schema validated and deploy the application as we wish to!==. Without `selector` no `rs`.  should definitely pass at least one or multiple values as selector.

**NOT LIKE `rc`**. there, it doesn't matter and all those PODs get deployed. Plus, if no `matchLabels` section declared under the spec section of `rc` (not the containers) the labels from the PodTemplate section's metadata labels gets taken into consideration and get assigned to the `rc` as labels for the selector to identify:

**What happens to the `rs`?**
if we apply the manifest, error can be seen.
```
The ReplicaSet "nginx-rs" is invalid:
* spec.selector: Required value
* spec.template.metadata.labels: Invalid value: map[string]string{"app":"nginx-app", "env":"prod", "release":"v1.0"}: `selector` does not match template `labels`
```
Throwing this error. Since, we didn't write any selector, it couldn't pass the manifest and deploy the application.

>This isn't `rc` that don't mind labels. 
>Selectors matters and mandatory for `rs` for it to identify the resources. 

WITHOUT WRITING A SELECTOR, YOU CANNOT DEPLOY `rs` in K8s.
Since, there is none here, `rs` couldn't get applied.

> If `rc`, we didn't write any selector and though it gets applied and the selector will be adapted by the labels that are given under the template section. AND THIS IS NOT THE CASE FOR `rs`

`rs-multicontainer+matchLabels.yaml`
```yaml
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: nginx-rs
  labels:
    app: nginx-app
    env: prod
    release: v1.0
  
spec:
  replicas: 3
  selector:
    matchLabels:
     app: nginx-app
     env: prod
     release: v1.0
     
  template:
    metadata:
      name: nginx-rs
      labels:
        app: nginx-app
        env: prod
        release: v1.0

    spec:
      containers:
      - name: write-app
        image: alpine
        command: ["/bin/sh"]
        args: ["-c", "while true; do date >> /var/log/index.html; sleep 10; done"]
        volumeMounts:
        - name: rc-shared-volume
          mountPath: /var/log

      - name: server-app
        image: nginx:latest
        ports:
        - containerPort: 80
        volumeMounts:
        - name: rc-shared-volume
          mountPath: /usr/share/nginx/html

      volumes:
      - name: rc-shared-volume
        emptyDir: {}
```

this gets applied in ease. 
++ those labels has to matchLabels in both the selector and in the metadata of PodTemplate, - to match the labels in the `spec.template.metadata.labels`.
- The `selector.matchLabels` determines which Pods the ReplicaSet manages.
- The `spec.template.metadata.labels` defines the labels assigned to Pods created by the ReplicaSet.
- These two must align for the ReplicaSet to manage its Pods properly.

Label mismatch - PODs will not be controlled by the `rs`

Apply the `rs` and verify the same.
```
kubectl get rs -o wide
kubectl get po -o wide --show-labels
```

Let play around by removing one of the label of `rs`, to do that,  run the same and pick one of the PODs Label: or simply `kubectl edit rs/rsName` to perform the same.

```
kubectl label pods PodName app-
```
will give the output of `POD unlabeled` - minus the label: `app`

AND,
```
kubectl get po -o wide --show-labels
```
now, you can able to see that the 
- unlabeled POD gets isolated, out of `rs`'s control to be orphaned.
- also the POD can be deleted, since it is not yet controlled by `rs`
- a new POD gets created  with the same labels.

WHY? if you want to do some patch, troubleshooting, run jobs inside the Container or such. But to perform the same outside a circle, isolate it by removing any one of the table and perform the same on a POD.

Delete, if needed. or bring back the same POD to the `rs`, after adding, the last one gets removed. Having a POD in isolation forever is of no use. To add back
```
kubectl label pods isolatedPodName app=label
```
you can re-add the Isolated POD with the `rs` by passing the same label.   

all will be back to default by old one getting associated with the `rs` and one of the least qualified POD gets terminated. 
> **THIS IS HOW `matchLabels` works for `rs`**

Later, we will see in brief about a similar concept name `matchedExpressions`

> [!NOTE]  ##### FINAL file - demo manifest of a multicontainer `replicationcontroller`.  RC - MANIFEST
> ###### multicontainer-rc.yaml.yaml
> ```yaml
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: nginx-rs
  labels:
    app: nginx-app
    env: prod
    release: v1.0
>
spec:
  replicas: 3
  selector:
    matchLabels:
     app: nginx-app
     env: prod
     release: v1.0
>
 template:
    metadata:
      name: nginx-rs
      labels:
        app: nginx-app
        env: prod
        release: v1.0
>
 spec:
      containers:
      - name: write-app
        image: alpine
        command: ["/bin/sh"]
        args: ["-c", "while true; do date >> /var/log/index.html; sleep 10; done"]
        volumeMounts:
        - name: rc-shared-volume
          mountPath: /var/log
>
      - name: server-app
        image: nginx:latest
        ports:
        - containerPort: 80
        volumeMounts:
        - name: rc-shared-volume
          mountPath: /usr/share/nginx/html
  >volumes:
      - name: rc-shared-volume
        emptyDir: {}

---
# 5) Demo: RS and POD Label selector (`matchExpressions`)

Understanding **`rs` Selector's `matchExpressions`** 
-- for `rs`.

So far, we have seen about the `matchLabels` and how to write it for `rs`. Now `matchExpressions`

For `matchExpressions`, 
**There are three parameters to define.** 
- Key 
- Operator
- Values
- 
These are the three major parameter factors for defining `matchExpressions` for `rs`.

| Key                                                                                  | Operator                                                                                                           | Values                                                                                    |
| ------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------ | ----------------------------------------------------------------------------------------- |
| `key_name`<br>key- just a variable like any other where you can store values within. | 1) `In`<br>2) `NotIn`<br>3) `Exist`<br>4) `DoesNotExists`,<br>these are the four operators in **matchExpressions** | `value1`<br>`value2`<br>one or more values you would like to store under a particular key |
Why these parameters and what are the logic behind this, 
-  Understanding of `key-value` pair is standard. will see how it works with the operators.
###### **`In` Operator**
- When you write/define a key, you will call in/write `In` Operator. Why?  with this
- **`Key`** + `In` Operator = can have **one or multiple `value`'s** within. 
- This operator works like `OR` condition where either one or more has to exist with that key.
> SHOULD MATCH ANY ONE OF THE VALUE

###### **`NotIn` Operator**:
- Opposite to `In` Operator. You defined a key and a value for it with the `NotIn` Operator. 
- `Key` + `NotIn` Operator = Key != (not equal to) value. Key should not be equal to the value. If the value is same, the `rs` doesn't launch the PODs or Such PODs cannot be controlled by `rs`. 
- can have multiple values too. But that should not match with the Key. 
- This operator works like `Not equal to` condition. 
> SHOULD NOT MATCH ANY OF THE VALUE.

For these `In`  and `NotIn` - have to right Key+ Value - one or more. like equal to, not equal to

###### `Exists` Operator: 
 - Just a key and nothing else. Even there are values, doesn't mind
 - Key
 - in the templateLabels, that's it!
 - With just a key in the PodTemplate, i can able to select the PODs managed by `rs`

###### `DoesNotExists` Operator: 
- Reverse of `Exist` Operator is `DoesNotExist` Operator
- If I define any key that under that `matchExpression` Selector, that POD will not be handled by `rs`.

For these `Exist` and `DoesNotExist`, Only `Key` expression. Just the `key` if **Exists**, it exists. If doesn't - **DoesNotExists**.  

##### Demo/Practical:

```yaml
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: nginx-rs
  labels:
    app: nginx-app
    env: prod
    release: v1.0

spec:
  replicas: 3
  selector:
    matchLabels:
     app: nginx-app
     env: prod
     release: v1.0

  template:
    metadata:
      name: nginx-rs
      labels:
        app: nginx-app
        env: prod
        release: v1.0

    spec:
      containers:
      - name: write-app
        image: alpine
        command: ["/bin/sh"]
        args: ["-c", "while true; do date >> /var/log/index.html; sleep 10; done"]
        volumeMounts:
        - name: rc-shared-volume
          mountPath: /var/log

      - name: server-app
        image: nginx:latest
        ports:
        - containerPort: 80
        volumeMounts:
        - name: rc-shared-volume
          mountPath: /usr/share/nginx/html

      volumes:
      - name: rc-shared-volume
        emptyDir: {}
```
Will re-use the same to get more of `matchExpressions`. 











