Section 10: K8s Cron Jobs
1. Introduction to CronJobs (cj)
		K8s workload resource Introduction to Cronjobs (cj) - [Doc]
2. CronJob workflow (restart Policy)
		CronJob workflow (restart Policy) - [Doc]
2. CronJob concurrency policy
4. CronJob Job history limits
		CronJob Job history limits - [Doc]
---

Section 10: K8s Cron Jobs
# 1. Introduction to CronJobs (cj)
K8s workload resource Introduction to Cronjobs (cj) - [Doc]

Following to Job which just executes Job after our command. How bout executing Jobs  as per schedule, based on specific times and such. Same Linux's `crontab` stuff. we have **CronJobs** to run the batch/shell script/job operation.

to understand the same in brief, must recall `Jobs`. 

WILL DIVE DEEPER INTO THE ==**CronJobs `cj`**== FOR OUR OPERATIONS.

> K8s Workload Resource:  ==**CronJobs `cj`**==

##### K8s Workload Resources: **Jobs** `jobs`
- CronJob is a workload resource which will ensure one or more Pods create and terminate successfully
- In general, we use `CronJobs` to run some batch operations like backups, restore, report generation etc., for scheduled time period (like `crontab`)
- Workflow: CronJob -> Job -> POD
- `apiVersion` for `cronjob` object is `batch/v1`
- all `CronJob` schedules are based on timezone of the `kube-controller-manager`
- CronJob uses `jobTemplate` to create `Jobs` followed by `podTemplate`
- we can set `.spec.timezone` to valid time zone to control the schedule of `CronTab`, if `CronJobTimeZone` feature gate enabled (v1.25 beta) -   (to make it work appropriately according to the timing.)
- We can suspend the `cronjob` as well and start again by `.spec.suspend` value to true or false. The command is
```
kubectl patch cronjob/<cronJob-name> --type=strategic --patch '{"spec":{"suspend": true}}'
```
- Cron schedules syntax:
```cron
<mins><hrs><dayOfTheMonth><month><dayOfTheWeek>
```
```
1) <minute>: 0 - 59
2) <hour>: 0 - 23
3) <day of the month>: 1 - 31
4) <month>: 1 - 12
5) <day of the week>: 0 - 6 (sun - sat or starting 3 letter of each)
```


##### 1. `CronJob` is a workload resource which will ensure one or more `Pods` create and terminate successfully
`Job` running a specific operation for that time. `Cron` is nothing but same to run operation scheduled time periodically to run the same on a basis.  


##### 2. In general, we use `CronJobs` to run some `batch` operations like *backups*, *restore*, *report generation* etc., for scheduled time period (like `crontab`)
We use `CronJobs` to run some `batch` operations like *backups*, *restore*, *report generation* etc., for scheduled time period (like `crontab`)


##### 3. Workflow: `CronJob` -> `Job` -> `POD`
since it is as same job but periodic. 
CronJob -> creates `Job` object -> creates `Pod` to run the execution


##### 4. `apiVersion` for `cronjob` object is `batch/v1`
```
apiVersion: batch/v1
kind: CronJob
```


##### 5. all `CronJob` schedules are based on time zone of the `kube-controller-manager`
Time zone used by `kube-controller-manager` = Time zone of `Cron`.

##### 6. CronJob uses `jobTemplate` to create `Jobs` followed by `podTemplate`
**`Cron`** ->` jobTemplate` -> **`Job`** ->  `PodTemplate` -> **`Pod`**


##### 7. we can set `.spec.timezone` to valid time zone to control the schedule of `CronTab`, if `CronJobTimeZone` feature gate enabled (v1.25 beta) -   (to make it work appropriately according to the timing.)
as we previously mentioned that, Time zone used by `kube-controller-manager` = Time zone of `Cron`.

Since the `Cron` is heavily depends on the Time and periods, timezone. We can set timezone here too. by enabling a feature `CronJobTimeZone` and declare the same under a param  `.spec.timezone`. Without enabling, can't use the same. 

##### 8. We can suspend the `cronjob` as well and start again by `.spec.suspend` value to true or false. The command is

same as we saw in the `Job`, we can suspend the same here too to `CronJob` if you don't want to run that Job. Using
```
kubectl patch cronjob/<cronJob-name> --type=strategic --patch '{"spec":{"suspend": true}}'
```

##### 9. Cron schedules syntax:
**The syntax of `CronJob`: (More of `crontab`)**
```cron
<mins><hrs><dateOfTheMonth><month><dayOfTheWeek>
```
```
11) <minute>: 0 - 59
12) <hour>: 0 - 23 (no12hrFormat)
13) <date of the month>: 1 - 31
14) <month>: 1 - 12
15) <day of the week>: 0 - 6 (sun - sat or starting 3 letter of each)
```

| mins | hrs  | dateOfTheMonth | month | dayOfTheWeek |
| ---- | ---- | -------------- | ----- | ------------ |
| 0-59 | 0-23 | 1-31           | 1-12  | 0-6/day      |

---
# 2. CronJob workflow (`restart Policy`)
CronJob workflow (restart Policy) - [Doc]

to check the available `apiVersion`'s objects to declare in the manifest. 
```
kubectl api-resources | grep resourceName
```
Lets create one. `cj.yaml` 
```yaml
apiVersion: batch/v1    #apiVersion for Jobs
kind: CronJob           #kind of object
metadata:               #all the boilerplate labels that to assign to the objects
  name: cj1             #name of the object as label
spec:
  schedule: "*/2 * * * *" #cron expression to schedule the job at a given time (every 2 minutes)
  timezone: "Asia/Kolkata" #timezone of the job
  jobTemplate:            #jobTemplate for the job
    spec:                 #spec of the job
      template:           #template for the job where you write PodTemplate spec
        spec:             #spec of the PodTemplate
          containers:     #containers of the PodTemplate
            - name: cj1    #name of the container
              image: ubuntu:latest #image of the container
              args:     #command to run in the container
                - /bin/bash
                - -c
                - date; echo Welcome to cronJob
           restartPolicy: OnFailure #restartPolicy of the container (restart the container if it fails)
```

verify resources:
```
kubectl get cj,jobs,po -o wide
```
```
watch kubectl get cj,jobs,po -o wide
```

Here,
```
NAME            cj1  #name of the job
SCHEDULE        */2 * * * * #cron expression
TIMEZONE        <none> #timezone
SUSPEND         False  #suspend
ACTIVE          0      #Jobs that ran 
LAST SCHEDULE   75s #lastJob's
AGE             2m20s #agr of cj  
CONTAINERS      cj1   #podsToRunCJ
IMAGES          ubuntu:latest #image
SELECTOR        <none> #selector
```
**Workflow**: `cj` --> triggers `jobs` at the given time -> jobs creates `Pods` to execute each job

here, it stops at a certain point of time. probably `3`, that is due to the limit set by a parameter `successfulJobsHistoryLimits: 3` WILL SEE ABOUT THIS DEDICATEDLY,

>While the jobs continues to does its thing, if you need to do an update or maintenance in-between, `suspend` the job.
```
kubectl edit cj/cjName
```
edit: `suspend=true`,

and verify back with, 
```
kubectl get cj,jobs,po -o wide
```
```
NAME            cj1  #name of the job
SCHEDULE        */2 * * * * #cron expression
...
SUSPEND         True  #suspend
...
```
jobs will be stopped and new ones will not be created. 

AND EVERY ASPECTS OF JOBS THAT WE HAVE SEEN ARE APPLIED HERE TOO: (delete the job or the POD, nothing happens and affects the `cron`, just the history of the `job` will be lost)
```
kubectl delete job/JobName
kubectl po pod/podName
```


**delete a `cronJob`**:
```
kubectl delete cj/cjName
```
when deleting a `cronJob`: deletes the `cron` -> `jobs` -> `pods`

THIS IS ALL ABOUT `CRON`,
- what is `cronJob`
- scheduling of `cronJob`
- handling the `cronJob`


---
# 3. CronJob Concurrency policy

Automated Tasks with `cron-jobs`

Next, 
UNDERSTANDING **`CronJob`'s Concurrency policy**, an optional field that runs under the parameter of `.spec.concurrencyPolicy` for `cronJob`,

What is  **Concurrency policy** in the first place?
CronJobs creates jobs at any given time, the `Concurrency policy` defines and controls when it has to create a `job`. The default is `Allow`.

To understand this use case in brief,
So, if a `CronJob` executes a `job` to perform a task via the
POD. meanwhile, another one gets triggered while the first job is still running. Another `CronJob` triggers the same does the the same and the cycle repeats. 

**Concurrency Policy is the same managing all the CLUTTER BETWEEN ONE AND OTHER.**

In this **Concurrency policy**, we have three modes:
- Allow
- Forbid
- Replace

1) `Allow` - It just works as it is, what we just declare. Allows multiple Jobs to do its task simultaneously and **concurrently** not to worry about the previous job at all.
2) `Forbid` -  Don't run another job if an old Job that is already is on the run performing its task.
3) `Replace` - Run the new job performing the task replacing the old running job by stopping it.

Apply the same based on the appropriate scenarios, if else just proceed with the default.

**Will see this in practice,** using the same base template manifest to verify the default `concurrencyPolicy`.

###### Allow:
```
apiVersion: batch/v1
kind: CronJob
metadata:
  name: cj1
spec:
  schedule: "*/2 * * * *"
  jobTemplate:
    spec:
      template:
        spec:
          containers:
            - name: cj1
              image: ubuntu:latest
              args:
                - /bin/bash
                - -c
                - date; echo Welcome to cronJob
           restartPolicy: OnFailure
#same base template manifest to verify the default concurrencyPolicy
```
apply,
```yaml
kubectl get po -o cj/cj.yaml
```

Will check the default `Concurrency Policy`:
```
kubectl get cj cjName -o yaml
kubectl get cj cjName -o yaml | grep concurrency
```
check the `concurrencyPolicy: Allow`, which has been applied by default.
>+ It keeps on piling up the Jobs and the PODs.

if to modify
```
kubectl edit cj cjName 
```
change the param to `ConcurrencyPolicy: `, save and exit. 

###### Replace:
==**The Older job gets terminated and `replace`d with with the new Jobs with an newID.==** 
to modify the `ConcurrencyPolicy: Replace`
imperatively,
```
kubectl edit cj cjName 
```
change the param to `ConcurrencyPolicy: Replace`, save and exit. 

or declaratively:
```
spec:
  concurrencyPolicy: Replace
  schedule: "*/2 * * * *"
  # timezone: "Asia/Kolkata"
  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: OnFailure

```

Will apply the same with different manifest with executing a logic where we can see the practice of the the `Replace` Functionality in ease. 

Job has to triggering a POD executing a task continuously which to get trashed and get replaced by the new one and the cycle goes. TO OBSERVE THE BEHAVIOUR OF `ConcurrencyPolicy: Replace`

```
apiVersion: batch/v1
kind: CronJob
metadata:
  name: cj1
spec:
  concurrencyPolicy: Replace
  schedule: "*/2 * * * *"
  # timezone: "Asia/Kolkata"
  jobTemplate:
    spec:
      template:
        spec:
          containers:
            - name: cj1
              image: ubuntu:latest
              args:
                - /bin/bash
                - -c
                - while true; do date; echo Welcome to cronJob ; sleep 10; done
          restartPolicy: OnFailure
```

after modifying, verify
```sh
kubectl get cj,jobs,po -o wide
watch kubectl get cj,jobs,po -o wide
kubectl get cj cjName -o yaml
```
```
kubectl logs podName
watch kubectl logs podName
```

resulting the old-pod to,
```
error - PodName not found in the namespace
```
**Will observe the function here, since the `ConcurrencyPolicy=Replace`, 
The Older job gets terminated and `replace`d with with the new Jobs with an newID.** 

THAT's WHATS UP!

###### Forbid,
another on is `Forbid`,
==**Don't run another job if an old Job that is already is on the run performing its task.==** 

same manifest but `concurrencyPolicy: Forbid`
```
apiVersion: batch/v1
kind: CronJob
metadata:
  name: cj-replace
spec:
  concurrencyPolicy: Forbid
  schedule: "*/2 * * * *"
  jobTemplate:
    spec:
      template:
        spec:
          containers:
            - name: cj-replace
              image: ubuntu:latest
              args:
                - /bin/bash
                - -c
                - while true; do date; echo Welcome to cronJob ; sleep 10; done
          restartPolicy: OnFailure
```

edit the manifest,
- either delete and create
- or
```
kubectl replace --force -f cj/cjName.yaml
```
showing, `deleted` and `replaced,`

verify resources,
```sh
kubectl get cj,jobs,po -o wide
watch kubectl get cj,jobs,po -o wide
kubectl get cj cjName -o yaml
```
```
kubectl logs podName
watch kubectl logs podName
```

CLEANUP:
```
kubectl delete cj cjName
```


---
# 4. CronJob Job history limits
CronJob Job history limits - [Doc]

```
kubectl create -f c/cjName.yaml
```
limiting the history/numbers/executions  of the `CronJobs`, whether it is successful or fail, 

The default values of `successfulJobsHistoryLimit`
If successful, `successfulJobsHistoryLimit: 3`
If fails, `Failed Job Histry Limit: 1`

To verify,
```
kubectl describe cj cjName
```

To modify these values where there should be no limits,
>there are not supposed to be stored in the `jobHistory`. The catch/condition is since these doesn't get stored in the history, we couldn't be able to pull up the records from the history to troubleshoot if required.

In order to do that, we should change and pass the `param` to
`successfulJobsHistoryLimit=0` BUT DON'T DO IT, INSTEAD JUST INCREASE THE LIMIT, 5MAX for success, 3MAX for fail. Do proceed with the default value itself.

To edit the values,
```
kubectl edit cj cjName
```
and simply change the params. 

*fin*

---